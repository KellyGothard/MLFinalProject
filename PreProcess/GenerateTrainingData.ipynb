{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will load 50000 banned examples and 50000 notbanned examples\n",
      "Train Test Split...\n",
      "Generating Data Frames\n",
      "   banned                                             tokens\n",
      "0       0  [to, escape, problems, by, playing, games, fin...\n",
      "1       1  [which, is, essentially, what, all, these, spe...\n",
      "2       1  [maximize, one, s, life, potential, Do, you, n...\n",
      "3       1  [backfire, on, their, faces, and, I, couldn, t...\n",
      "4       0  [it, wouldn, t, have, changed, anything, I, th...\n",
      "   banned                                             tokens\n",
      "0       1  [fine, I, repeat, in, as, clear, terms, as, po...\n",
      "1       0  [looking, to, make, right, now, is, a, 255, hp...\n",
      "2       1  [because, the, slavs, would, be, wiped, out, F...\n",
      "3       1  [cheese, and, broccoli, and, cheese, ones, I, ...\n",
      "4       0  [Filthy, Frank, and, Ezra, Miller, are, cousin...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# How many words per training example?\n",
    "SEQLEN = 200\n",
    "\n",
    "# How many training examples of each type?\n",
    "bannedCnt = 50000\n",
    "notbannedCnt = 50000\n",
    "\n",
    "\n",
    "# where are the source files?\n",
    "# These are generated by PreProcessComments.py\n",
    "banned_txt = \"../Data/RC_2016-10_banned.txt\"\n",
    "notbanned_txt = \"../Data/RC_2016-10_notbanned.txt\"\n",
    "\n",
    "# open the source files.\n",
    "bannedF = open(banned_txt,\"r\")\n",
    "notbannedF = open(notbanned_txt, \"r\")\n",
    "\n",
    "# log progress.\n",
    "print(\"Will load %d banned examples and %d notbanned examples\"%(bannedCnt, notbannedCnt))\n",
    "\n",
    "# load the training examples\n",
    "all_posts = []\n",
    "bannedPosts = [(1, [bannedF.readline().strip() for _ in range(SEQLEN)]) for _ in range(bannedCnt)]\n",
    "notbannedPosts  = [(0, [notbannedF.readline().strip() for _ in range(SEQLEN)]) for _ in range(notbannedCnt)]\n",
    "\n",
    "all_posts += bannedPosts\n",
    "all_posts += notbannedPosts\n",
    "\n",
    "print(\"Train Test Split...\")\n",
    "# split to have about 10K in the test set.\n",
    "train, test = train_test_split(all_posts, test_size=0.1)\n",
    "\n",
    "\n",
    "print(\"Generating Data Frames\")\n",
    "dfTrain= pd.DataFrame(train, columns=[\"banned\", \"tokens\"])\n",
    "dfTest = pd.DataFrame(test, columns=[\"banned\", \"tokens\"])\n",
    "\n",
    "print(dfTrain.head())\n",
    "print(dfTest.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
