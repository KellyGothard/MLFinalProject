{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORTS #####\n",
    "from string import punctuation\n",
    "from collections import deque\n",
    "from datetime import timedelta\n",
    "import ujson\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "# import praw\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from sklearn.svm import SVC\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import argparse\n",
    "import gzip\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import time\n",
    "import numpy as np\n",
    "import bz2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BANNED_LOC = \"../Data/banned_reddits.txt\"\n",
    "banned_dict = {}\n",
    "with open(BANNED_LOC) as f:\n",
    "    for l in f:\n",
    "        banned_dict[l.strip()[2:]] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotive ratings for sample words.\n",
      "dead 2.02\n",
      "cry 3.22\n",
      "party 7.18\n",
      "born 7.33\n",
      "sleep 7.22\n"
     ]
    }
   ],
   "source": [
    "# Read in the ~14000 emotive words that have been rated. Generate a dictionary for reference.\n",
    "EMOT_LOC = \"../Data/BRM-emot-submit.csv\"\n",
    "emote_df = pd.read_csv(EMOT_LOC)\n",
    "emot_arr = emote_df[[\"Word\", \"V.Mean.Sum\"]].values\n",
    "\n",
    "emot_dict = {}\n",
    "for word, value in emot_arr:\n",
    "    emot_dict[word] = value\n",
    "    \n",
    "def clean_text(text):\n",
    "    exclude = set(punctuation) # Keep a set of \"bad\" characters.\n",
    "    list_letters_noPunct = [ char for char in text if char not in exclude ]\n",
    "    \n",
    "    # Now we have a list of LETTERS, *join* them back together to get words:\n",
    "    text_noPunct =  \"\".join(list_letters_noPunct)\n",
    "\n",
    "    # Split this big string into a list of words:\n",
    "    list_words = text_noPunct.strip().split()\n",
    "    \n",
    "    # Convert to lower-case letters:\n",
    "    list_words = [ word.lower() for word in list_words ]\n",
    "    return list_words\n",
    "\n",
    "def get_emotion(word_list):\n",
    "    vals = [emot_dict[word] for word in word_list if word in emot_dict]\n",
    "    if len(vals) == 0:\n",
    "        return np.nan, np.nan\n",
    "    else:\n",
    "        return np.mean(np.array(vals)), np.sum(np.array(vals))\n",
    "    \n",
    "print(\"Emotive ratings for sample words.\")\n",
    "\n",
    "\n",
    "for word in [ \"dead\",\"cry\", \"party\",  \"born\", \"sleep\"]:\n",
    "    print(word, emot_dict[word])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took: 33.83\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "# make a queue much faster than list for adding large amounts of items.\n",
    "q = deque()\n",
    "\n",
    "# Read in JSON data\n",
    "NUM_POSTS_TO_READ = 2e5\n",
    "MSG_PREV = 30\n",
    "\n",
    "with bz2.open(\"../Data/RC_2016-10.bz2\") as f:\n",
    "    num_read = 0\n",
    "    for line in f:\n",
    "        num_read += 1\n",
    "        if num_read > NUM_POSTS_TO_READ: break\n",
    "        post = ujson.loads(line)\n",
    "        post[\"banned\"] = True if post[\"subreddit\"] in banned_dict else False\n",
    "        cleaned_text = clean_text(post[\"body\"])\n",
    "        emot_avg, emot_sum  = get_emotion(cleaned_text)\n",
    "        post[\"emotionAvg\"] = emot_avg \n",
    "        post[\"emotionSum\"] = emot_sum\n",
    "        post[\"bodySan\"] = ' '.join(cleaned_text)\n",
    "        q.append(post)\n",
    "\n",
    "df = pd.DataFrame(q)\n",
    "t1 = time.time()\n",
    "print(\"took: %.2f\"%(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B  posts have avg per post emotion of mean:    5.64, std: 0.84\n",
      "NB posts have avg per post emotion of mean:    5.77, std: 0.80\n",
      "B  posts have summed per post emotion of mean: 43.21, std: 56.67\n",
      "NB posts have summed per post emotion of mean: 51.71, std: 85.05\n"
     ]
    }
   ],
   "source": [
    "# print the dataframe\n",
    "df[[\"subreddit\", \"author\", \"body\",\"bodySan\", \"banned\", \"emotionAvg\", \"emotionSum\"]]\n",
    "\n",
    "tmpBanned = df.iloc[np.where(df[\"banned\"])]\n",
    "tmpNotBanned = df.iloc[np.where(df[\"banned\"] != True)]\n",
    "\n",
    "print(\"B  posts have avg per post emotion of mean:    %4.2f, std: %4.2f\"%(np.nanmean(tmpBanned[\"emotionAvg\"]), np.nanstd(tmpBanned[\"emotionAvg\"]) ))\n",
    "print(\"NB posts have avg per post emotion of mean:    %4.2f, std: %4.2f\"%(np.nanmean(tmpNotBanned[\"emotionAvg\"]), np.nanstd(tmpNotBanned[\"emotionAvg\"]) ))\n",
    "\n",
    "print(\"B  posts have summed per post emotion of mean: %4.2f, std: %4.2f\"%(np.nanmean(tmpBanned[\"emotionSum\"]), np.nanstd(tmpBanned[\"emotionSum\"])))\n",
    "print(\"NB posts have summed per post emotion of mean: %4.2f, std: %4.2f\"%(np.nanmean(tmpNotBanned[\"emotionSum\"]), np.nanstd(tmpNotBanned[\"emotionSum\"])))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hookers           \"Services are free! Fuck I'll fly there if the\"                                                     \n",
      "watchpeopledie    \"too bad he wasn't\"                                                                                 \n",
      "DarkNetMarkets    'Not from him. Checked my track'                                                                    \n",
      "fakeid            '420'                                                                                               \n",
      "CringeAnarchy     'fuck is this gay shit'                                                                             \n",
      "proED             '**0830** \\n\\n* weetabix (134) + almond milk (23'                                                   \n",
      "fakeid            \"still haven't received my AK and U21 MS :(\"                                                        \n",
      "CringeAnarchy     \"I don't understand.  Then again I'm not a FUC\"                                                     \n",
      "Incel             \"I'm actually a normie but good post\"                                                               \n"
     ]
    }
   ],
   "source": [
    "\n",
    "tmpBanned = df.iloc[np.where(df[\"banned\"])]\n",
    "for row in tmpBanned[[\"subreddit\", \"author\", \"emotionAvg\",  \"body\",]].values[50:60]:\n",
    "    if row[-1] == \"[deleted]\" or row[-1] == \"[removed]\":\n",
    "        continue\n",
    "    print (\"%-15s\"%row[0][:15], \"  %-100s\"%repr(row[-1][:45]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poker             'Okay.. haha im confused'                                                                           \n",
      "baseball          'JD Drew kind of'                                                                                   \n",
      "unitedkingdom     \"Performance enhancing that's why.\"                                                                 \n",
      "interestingasfu   'He farts out of his eyes?!!'                                                                       \n",
      "The_Donald        '*Someone* gets it ..\\n\\n'                                                                          \n",
      "politics          \"&gt;Dollar coins finally catch on thanks to triumphant RenFaire nerds. \\n\\nAlright, let's try to be a little more realistic here...\"\n",
      "madisonwi         'When was the last time you were at Red Letter News?\\n'                                             \n",
      "worldnews         'apparently PETA euthanize an enormous amount of animals they \"rescue\"'                             \n",
      "freemasonry       \"There's always been a demand for male-only spaces. A demand for male-only clown spaces is another topic altogether. \"\n",
      "PhascinatingPhy   \"That's actually pretty cool and the way that CrazyRussianHacker does this experiment is hilarious and it makes it easier to pay attention and understand the concept. The fact that it has the possibility to be done with a garbage bag makes it way better because it means you can do it at home.  So the air inside the bag will be heated up by the sun because the bag is black, and this causes the temperature to rise inside and since heat rises, the bag floats up. When the air cools down or the sun is covered, the balloon falls because it is returning to the state at which it is the same as normal air.  No helium required!\"\n"
     ]
    }
   ],
   "source": [
    "tmpNotBanned = df.iloc[np.where(df[\"banned\"] != True)]\n",
    "\n",
    "for row in tmpNotBanned[[\"subreddit\", \"author\", \"emotionAvg\",  \"body\",]].values[20:30]:\n",
    "    if row[-1] == \"[deleted]\" or row[-1] == \"[removed]\":\n",
    "        continue\n",
    "    print (\"%-15s\"%row[0][:15], \"  %-100s\"%repr(row[-1][:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
