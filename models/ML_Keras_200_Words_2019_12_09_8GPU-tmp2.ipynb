{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "##### Always import all needed libraries in the first cell\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import os\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Reshape\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(1) # this sets the seed so that the runs are consistent\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(clf,X,y,name):\n",
    "    print(name)\n",
    "    y_pred = cross_val_predict(clf, X, y, cv=10)\n",
    "    print(metrics.classification_report(y, y_pred))\n",
    "    conf = np.array(metrics.confusion_matrix(y, y_pred))\n",
    "    print(conf)\n",
    "    y_probas = clf.predict_proba(X)\n",
    "#     skplt.metrics.plot_roc_curve(y, y_probas, title=name+' ROC Curves', curves='each_class')\n",
    "    return metrics.f1_score(y,y_pred,pos_label=1, average='binary')\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "def binary_focal_loss(gamma=2., alpha=.25):\n",
    "    \"\"\"\n",
    "    Binary form of focal loss.\n",
    "      FL(p_t) = -alpha * (1 - p_t)**gamma * log(p_t)\n",
    "      where p = sigmoid(x), p_t = p or 1 - p depending on if the label is 1 or 0, respectively.\n",
    "    References:\n",
    "        https://arxiv.org/pdf/1708.02002.pdf\n",
    "    Usage:\n",
    "     model.compile(loss=[binary_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
    "    \"\"\"\n",
    "    def binary_focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        :param y_true: A tensor of the same shape as `y_pred`\n",
    "        :param y_pred:  A tensor resulting from a sigmoid\n",
    "        :return: Output tensor.\n",
    "        \"\"\"\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "\n",
    "        epsilon = K.epsilon()\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        pt_1 = K.clip(pt_1, epsilon, 1. - epsilon)\n",
    "        pt_0 = K.clip(pt_0, epsilon, 1. - epsilon)\n",
    "\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) \\\n",
    "               -K.sum((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "\n",
    "    return binary_focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test percent lost: 5.63\n"
     ]
    }
   ],
   "source": [
    "dftrain_banned = pd.read_csv(\"../Data/Generated/200_words_10M_banned.csv\", delimiter=',')\n",
    "dftrain_banned.insert(0, \"banned\", 1)\n",
    "\n",
    "dftrain_notbanned = pd.read_csv(\"../Data/Generated/200_words_10M_notbanned.csv\", delimiter=',')\n",
    "dftrain_notbanned.insert(0, \"banned\", 0)\n",
    "\n",
    "dfTest = pd.read_csv(\"../Data/Generated/200_words_10M_test.csv\", delimiter=',')\n",
    "dfTest = dfTest.sample(frac=1)\n",
    "\n",
    "dfTest[\"split\"] = dfTest[\"words\"].map(lambda x: x.split(\" \"), na_action='ignore')\n",
    "dfTest[\"word_cnt\"] = dfTest[\"split\"].map(lambda x: len(x), na_action='ignore')\n",
    "print(\"Test percent lost: %.2f\" % (100*len(dfTest[dfTest[\"word_cnt\"] != 200])/ len(dfTest)))\n",
    "dfTest = dfTest[dfTest[\"word_cnt\"] == 200]\n",
    "\n",
    "dfTest_banned = dfTest[dfTest[\"banned\"]]\n",
    "dfTest_notbanned = dfTest[dfTest[\"banned\"] == False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BALANCE_RATIO = 20\n",
    "TEST_BALANCE_RATIO = 1\n",
    "TRAIN_N_COMMENTS = int(len(dftrain_banned)/5)\n",
    "TEST_N_COMMENTS = int(len(dfTest_banned)/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest_balanced = pd.concat([dfTest_banned.head(n=TEST_N_COMMENTS), dfTest_notbanned.head(n=TEST_BALANCE_RATIO*TEST_N_COMMENTS)]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrain = pd.concat([dftrain_banned.head(n=TRAIN_N_COMMENTS), dftrain_notbanned.head(n=TRAIN_BALANCE_RATIO*TRAIN_N_COMMENTS)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1500, 2), (30000, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain[dfTrain[\"banned\"]==1].shape, dfTrain[dfTrain[\"banned\"]==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train percent lost: 0.11\n"
     ]
    }
   ],
   "source": [
    "dfTrain[\"split\"] = dfTrain[\"words\"].apply(lambda x: x.split(\" \"))\n",
    "dfTrain[\"word_cnt\"] = dfTrain[\"split\"].apply(lambda x: len(x))\n",
    "print(\"Train percent lost: %.2f\" % (100*len(dfTrain[dfTrain[\"word_cnt\"] != 200])/ len(dfTrain)))\n",
    "dfTrain = dfTrain[dfTrain[\"word_cnt\"]== 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>banned</th>\n",
       "      <th>words</th>\n",
       "      <th>split</th>\n",
       "      <th>word_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20661</th>\n",
       "      <td>0</td>\n",
       "      <td>the best way to address our issues . Do n't tr...</td>\n",
       "      <td>[the, best, way, to, address, our, issues, ., ...</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18962</th>\n",
       "      <td>0</td>\n",
       "      <td>only one episode . what does one thing have to...</td>\n",
       "      <td>[only, one, episode, ., what, does, one, thing...</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6636</th>\n",
       "      <td>0</td>\n",
       "      <td>. Maybe he should n't act like a douche bag an...</td>\n",
       "      <td>[., Maybe, he, should, n't, act, like, a, douc...</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>0</td>\n",
       "      <td>it . Freezing rain , we get that once in a whi...</td>\n",
       "      <td>[it, ., Freezing, rain, ,, we, get, that, once...</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5617</th>\n",
       "      <td>0</td>\n",
       "      <td>to . ^ This guy gets it . [ ] ( /derpyhappy ) ...</td>\n",
       "      <td>[to, ., ^, This, guy, gets, it, ., [, ], (, /d...</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>0</td>\n",
       "      <td>was *that good* . Which makes it even more of ...</td>\n",
       "      <td>[was, *that, good*, ., Which, makes, it, even,...</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7427</th>\n",
       "      <td>0</td>\n",
       "      <td>humanity is Voldemort 's defining trait ! So t...</td>\n",
       "      <td>[humanity, is, Voldemort, 's, defining, trait,...</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>0</td>\n",
       "      <td>the end it 's not fair to evaluate individuals...</td>\n",
       "      <td>[the, end, it, 's, not, fair, to, evaluate, in...</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23243</th>\n",
       "      <td>0</td>\n",
       "      <td>watching TNG I always thought they were saying...</td>\n",
       "      <td>[watching, TNG, I, always, thought, they, were...</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>did someone do some solid testing on this ? Th...</td>\n",
       "      <td>[did, someone, do, some, solid, testing, on, t...</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       banned                                              words  \\\n",
       "20661       0  the best way to address our issues . Do n't tr...   \n",
       "18962       0  only one episode . what does one thing have to...   \n",
       "6636        0  . Maybe he should n't act like a douche bag an...   \n",
       "2083        0  it . Freezing rain , we get that once in a whi...   \n",
       "5617        0  to . ^ This guy gets it . [ ] ( /derpyhappy ) ...   \n",
       "9976        0  was *that good* . Which makes it even more of ...   \n",
       "7427        0  humanity is Voldemort 's defining trait ! So t...   \n",
       "1708        0  the end it 's not fair to evaluate individuals...   \n",
       "23243       0  watching TNG I always thought they were saying...   \n",
       "22          0  did someone do some solid testing on this ? Th...   \n",
       "\n",
       "                                                   split  word_cnt  \n",
       "20661  [the, best, way, to, address, our, issues, ., ...       200  \n",
       "18962  [only, one, episode, ., what, does, one, thing...       200  \n",
       "6636   [., Maybe, he, should, n't, act, like, a, douc...       200  \n",
       "2083   [it, ., Freezing, rain, ,, we, get, that, once...       200  \n",
       "5617   [to, ., ^, This, guy, gets, it, ., [, ], (, /d...       200  \n",
       "9976   [was, *that, good*, ., Which, makes, it, even,...       200  \n",
       "7427   [humanity, is, Voldemort, 's, defining, trait,...       200  \n",
       "1708   [the, end, it, 's, not, fair, to, evaluate, in...       200  \n",
       "23243  [watching, TNG, I, always, thought, they, were...       200  \n",
       "22     [did, someone, do, some, solid, testing, on, t...       200  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain = dfTrain.sample(frac=1)\n",
    "dfTrain.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(dfTrain[\"words\"])\n",
    "y_train = dfTrain[\"banned\"]\n",
    "\n",
    "X_test = vectorizer.transform(dfTest_balanced[\"words\"])\n",
    "y_test = dfTest_balanced[\"banned\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31466, 142111)\n",
      "142111\n",
      "WARNING:tensorflow:From /users/d/m/dmatthe1/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /users/d/m/dmatthe1/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /users/d/m/dmatthe1/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /users/d/m/dmatthe1/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /users/d/m/dmatthe1/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]  # Number of features\n",
    "print(X_train.shape)\n",
    "print(input_dim)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(layers.Dense(30, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(100, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(100, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "\n",
    "# model.add(layers.Dense(100, input_dim=input_dim, activation='relu'))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
    "# model.add(layers.Dense(100, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /users/d/m/dmatthe1/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /users/d/m/dmatthe1/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-2-9eead89c3a2c>:45: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "dense_1_input (InputLayer)      (None, 142111)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 142111)       0           dense_1_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 142111)       0           dense_1_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 142111)       0           dense_1_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 142111)       0           dense_1_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 142111)       0           dense_1_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 142111)       0           dense_1_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 142111)       0           dense_1_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 142111)       0           dense_1_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 1)            4277581     lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Concatenate)           (None, 1)            0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "                                                                 sequential_1[3][0]               \n",
      "                                                                 sequential_1[4][0]               \n",
      "                                                                 sequential_1[5][0]               \n",
      "                                                                 sequential_1[6][0]               \n",
      "                                                                 sequential_1[7][0]               \n",
      "                                                                 sequential_1[8][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,277,581\n",
      "Trainable params: 4,277,581\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "parallel_model = multi_gpu_model(model, gpus=8, cpu_merge=False)\n",
    "\n",
    "parallel_model.compile(#loss='binary_crossentropy',\n",
    "              loss=[binary_focal_loss(alpha=.25, gamma=2)],\n",
    "              optimizer='adam',\n",
    "              metrics=['acc',f1_m,precision_m, recall_m] )\n",
    "\n",
    "callbacks = [ModelCheckpoint(\"../Data/Models/weights.{epoch:02d}-{val_acc:.2f}.hdf5\", monitor=\"val_acc\", save_best_only=True),\n",
    "                        EarlyStopping(monitor=\"val_loss\", min_delta = 0, patience=10)]\n",
    "parallel_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31466 samples, validate on 3714 samples\n",
      "Epoch 1/100\n",
      "31466/31466 [==============================] - 46s 1ms/step - loss: 102.4236 - acc: 0.9285 - f1_m: 0.0039 - precision_m: 0.0021 - recall_m: 0.0290 - val_loss: 69.8739 - val_acc: 0.5000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 2/100\n",
      "31466/31466 [==============================] - 31s 994us/step - loss: 27.5997 - acc: 0.9533 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 160.6693 - val_acc: 0.5000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 3/100\n",
      "31466/31466 [==============================] - 30s 961us/step - loss: 19.0456 - acc: 0.9533 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 122.2221 - val_acc: 0.5000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 4/100\n",
      "31466/31466 [==============================] - 31s 975us/step - loss: 14.0551 - acc: 0.9533 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 111.8254 - val_acc: 0.5000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 5/100\n",
      "31466/31466 [==============================] - 31s 991us/step - loss: 9.7367 - acc: 0.9533 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 105.5070 - val_acc: 0.5000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 6/100\n",
      "31466/31466 [==============================] - 31s 987us/step - loss: 6.3708 - acc: 0.9538 - f1_m: 0.0178 - precision_m: 0.2515 - recall_m: 0.0093 - val_loss: 137.6415 - val_acc: 0.5000 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 7/100\n",
      "31466/31466 [==============================] - 31s 980us/step - loss: 4.2925 - acc: 0.9664 - f1_m: 0.4190 - precision_m: 0.9807 - recall_m: 0.2877 - val_loss: 160.1037 - val_acc: 0.6524 - val_f1_m: 0.4711 - val_precision_m: 0.9846 - val_recall_m: 0.3096\n",
      "Epoch 8/100\n",
      "31466/31466 [==============================] - 31s 984us/step - loss: 2.6704 - acc: 0.9867 - f1_m: 0.8354 - precision_m: 0.9716 - recall_m: 0.7386 - val_loss: 194.6619 - val_acc: 0.6634 - val_f1_m: 0.4972 - val_precision_m: 0.9826 - val_recall_m: 0.3329\n",
      "Epoch 9/100\n",
      "31466/31466 [==============================] - 31s 976us/step - loss: 1.9994 - acc: 0.9913 - f1_m: 0.8970 - precision_m: 0.9791 - recall_m: 0.8292 - val_loss: 199.7135 - val_acc: 0.6863 - val_f1_m: 0.5479 - val_precision_m: 0.9807 - val_recall_m: 0.3802\n",
      "Epoch 10/100\n",
      "31466/31466 [==============================] - 31s 995us/step - loss: 1.3360 - acc: 0.9942 - f1_m: 0.9326 - precision_m: 0.9860 - recall_m: 0.8858 - val_loss: 225.0770 - val_acc: 0.6788 - val_f1_m: 0.5320 - val_precision_m: 0.9799 - val_recall_m: 0.3652\n",
      "Epoch 11/100\n",
      "31466/31466 [==============================] - 31s 982us/step - loss: 1.1851 - acc: 0.9944 - f1_m: 0.9362 - precision_m: 0.9858 - recall_m: 0.8922 - val_loss: 236.9462 - val_acc: 0.6753 - val_f1_m: 0.5241 - val_precision_m: 0.9810 - val_recall_m: 0.3577\n"
     ]
    }
   ],
   "source": [
    "history = parallel_model.fit(X_train, y_train,\n",
    "                    epochs=100,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test[:10000], y_test[:10000]),\n",
    "                    callbacks = callbacks,\n",
    "                    batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model.save(\"weights-20-ratio.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "def cross_val_keras(clf,X,y,name):\n",
    "    print(name)\n",
    "    y_pred = cross_val_predict(clf, X, y, cv=10)\n",
    "    print(metrics.classification_report(y, y_pred))\n",
    "    conf = np.array(metrics.confusion_matrix(y, y_pred))\n",
    "    print(conf)\n",
    "    y_probas = clf.predict_proba(X)\n",
    "#     skplt.metrics.plot_roc_curve(y, y_probas, title=name+' ROC Curves', curves='each_class')\n",
    "    return metrics.f1_score(y,y_pred,pos_label=1, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_keras(model, X_test, y_test, 'Model')\n",
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAFACAYAAAC/abrtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xt8zvX/x/HHtV072nnDkkPllA2JOSTlNMwpcowiOSUkSol0UqQcI3KMDt+QUyrHrx8q5BhhU/imUoQdbHa0a9fn94dcGWMb265r2/N+u7nZ9Tk+P59re++1z/X+vD8mwzAMRERERESKOSd7BxARERERcQQqjEVEREREUGEsIiIiIgKoMBYRERERAVQYi4iIiIgAKoxFRERERAAVxvnu559/xmQysW/fvlytFxwczOTJk/MpVcEpiONITU3FZDKxYsWKXO33scceo127dre9/w0bNmAymYiOjr7tbYlI0aH2X+1/XsqrzHJzZnsHsDeTyXTT+RUqVOC333675e1XrlyZM2fOEBQUlKv1Dh8+TIkSJW55v8Vdfpw/i8WCi4sLS5Ys4bHHHrNNb9asGWfOnCEwMDBP9yci+Uvtf9Gk9l9uR7EvjM+cOWP7es+ePXTo0IE9e/ZQrlw5AJydnbNc79KlS7i6uma7fWdnZ4KDg3Odq2TJkrleR/5VkOfP1dX1lt7joiSnPw8ijkTtf9Gk9l9uR7HvShEcHGz7FxAQAFz+oboy7coPWHBwMG+++SYDBw4kICCA5s2bAzB58mRq1qxJiRIlKFOmDE888QTnzp2zbf/aj9KuvF61ahWtW7fG09OTSpUqsWzZsutyXf1RUHBwMOPHj2fIkCH4+fkRHBzM6NGjsVqttmWSkpLo27cvPj4+BAQEMGzYMF544QWqV69+03OQ3TFc+aho69atPPjgg3h4eFCjRg22bt2aaTv79++nfv36uLm5ce+99/Lll1/edL8xMTG4ubmxatWqTNN/++03nJyc2LZtGwAff/wxdevWxcfHh5IlS/LII4/wv//976bbvvb8nT9/ns6dO+Pp6UlwcDDjxo27bp1169bx8MMPExAQgJ+fH82aNePHH3+0zS9btiwAPXr0wGQy4e7unun8XP1R2vbt22nUqBHu7u4EBATQu3dvYmJibPNffvllqlevzvLly6lSpQpeXl6Eh4fz+++/3/S4sssIkJCQwNChQ7nzzjtxc3PjnnvuyXQuzpw5Q+/evSlVqhTu7u7ce++9fPbZZzc8FovFgslkYunSpcC/38PLli2jZcuWeHp6Mm7cONLT0+nXrx/33HMPHh4eVKxYkddff5309PRM+TZs2MCDDz6Ip6cnfn5+NG3alD/++IP169fj6urK2bNnMy0/d+5c/P39SUlJuem5Eckttf9q/68oDO3/tQzD4J133uGuu+7C1dWVSpUqMWvWrEzLrFixgvvuuw9PT0/8/f154IEHOHLkCABpaWkMGzbM9ruiTJkyPPnkk7nKUBQV+8I4N6ZMmUKFChXYvXs38+bNA8DJyYnp06dz5MgRli9fzrFjx+jVq1e22xo1ahQDBgzg0KFDtG/fnt69e2f7QzFlyhTuuece9u7dy6RJk3jvvfcyNagjRoxg48aNLF26lJ07d+Li4sKCBQuyzZLTYxg5ciRvvPEGP/30E6GhoXTt2pXExEQALl68SOvWrbnjjjvYu3cvCxYs4K233uLChQs33G9gYCBt2rTh448/zjT9s88+o3z58jRu3Bi4fHXmzTff5MCBA2zYsIH09HQeeeQRLBZLtsd2Re/evYmMjGT9+vVs3ryZI0eOsG7dukzLJCUlMXz4cHbv3s327dspW7YsERERxMfHA3DgwAEA5syZw5kzZ274fp06dYpWrVpRqVIl9u3bx+rVq9m7d2+mj98Afv/9dxYvXsyyZcv47rvv+Pvvvxk4cOBNjyO7jFarlYiICDZt2sTcuXM5evQoCxcutP3ST0xM5KGHHuLnn39m6dKlREVFMW3aNNzc3HJ8Lq946aWX6Nu3L5GRkfTv35+MjAzKli3LsmXLOHr0KJMnT2b27NmZfkGtW7eOtm3b0rBhQ3bt2sXOnTvp0aMH6enptGrVijvvvJPFixdn2s+CBQt44okn8PDwyHVGkbyi9l/tP9i3/b/W1KlTefvtt3n99deJjIxk+PDhjBgxgv/85z8A/PHHHzz22GO2dnrHjh0MHjzY9knIlClT+Prrr1myZAnHjx/nyy+/JCwsLFcZiiRDbL7//nsDME6ePHndvNKlSxtt2rTJdhs7d+40ACM6OtowDMM4evSoARh79+7N9HrWrFm2ddLS0gxXV1dj8eLFmfY3adKkTK+7du2aaV+NGzc2+vTpYxiGYcTGxhpms9n47LPPMi1Tq1YtIzQ0NNvcNzuG9evXG4Cxdu1a2zInT540AGPbtm2GYRjGzJkzDV9fXyMhIcG2zN69ew0g03Fca/Xq1YaLi4tx/vx527QqVaoYY8eOveE6p0+fNgBj3759hmEYRkpKigEYy5cvty1z9fk7fPiwARjfffedbX5ycrJRsmRJo23btjfcT3p6uuHp6WmsWLHC9howlixZkmm5K+fnyjGMHDnSuPvuu4309HTbMrt27TIAY/fu3YZhGMaoUaMMV1dXIzY21rbMokWLDLPZbFgslhtmyi7jN998YwDGoUOHslz+gw8+MEqUKGH8/fffWc6/9liyOu4r38PvvfdetvkmTJhgVK9e3fY6LCzM6Ny58w2XHz9+vFGpUiXDarUahmEYBw8evOnxiOQVtf9ZH4Paf8dp/7t3754pc1BQkPHqq69mWmbQoEFGtWrVDMO4/F6aTCbj9OnTWW5v4MCBRkREhK29lct0xTgX6tWrd920zZs306JFC8qVK4e3tzfh4eEA2f71X6tWLdvXrq6uBAUFXfcR8s3WAbjzzjtt6xw7dgyLxUKDBg0yLXPt66zk9Biu3v+dd94JYNt/VFQUNWrUwNvb27ZMWFhYtlf52rZti4+PD0uWLAFg9+7dHDt2jN69e9uW2b9/Px06dOCuu+7C29ubypUrZ5nvRqKionBycsp0Ljw8PKhdu3am5Y4fP07Pnj2pWLEiPj4++Pn5kZKSkuuPtyIjI2nYsCFm879d+OvVq4e7uzuRkZG2aRUqVMDf39/2+s4778RisWT6yO1a2WXcv38/d9xxBzVq1Mhy/f3791OzZk1Kly6dq2PKSlY/D7Nnz6Zu3bqUKlUKLy8v3nzzTVs2wzA4cOAALVu2vOE2+/bty++//277GHX+/PnUr1//hscjUlDU/qv9z4n8bP+vdu7cOaKjo3n44YczTW/cuDHHjx8nPT2dunXr0rhxY6pWrUrnzp2ZOXMmf/31l23Z/v37s2fPHqpUqcLgwYNZvXr1dV3fiiMVxrlw7V2uJ06coF27dlStWpVly5axb98+li9fDlz++Odmrr1xw2QyZeovdqvrZHeX9bVycwxX7//Kfq7s3zCMLPdtGMZN9+/i4kKPHj345JNPAPjkk0944IEHbI1ffHw8LVq0wN3dnY8//pi9e/eyc+fOLPPdSHYZrmjdujVnz55lzpw57Nq1i4MHD+Lr65vj/VztRu/D1dOzej+Bm34f5CRjdt8DN5vv5HS5Sbj6nN2oobz25+HTTz/l+eefp1evXqxfv54DBw4watSo687fzfYfHBxMhw4dmD9/PikpKfznP//J9ceLIvlB7b/a/5zKr/Y/J/u6+njNZjNbtmxh06ZN3H///SxdupTKlSvz3//+F4C6devy22+/MXHiRJycnBgyZAhhYWEkJSXlKkNRo8L4NuzevZv09HSmT59Ow4YNqVq1Kn///bddslSpUgWz2cwPP/yQafquXbtuul5eHUNoaCiHDh2y9TmDy3/pp6amZrtu79692bdvH4cOHWLZsmWZOv8fOXKEuLg4Jk6cSOPGjbn33ntzPV5kaGgoVqs107lITU3NdGPFX3/9xf/+9z/Gjh1LixYtCAkJwcnJKVMfOWdnZ5ydncnIyMh2fzt27MjUB27Pnj2kpqYSGhqaq+xXy0nGOnXqcPr0aQ4fPpzlNurUqcNPP/10w6tTpUqVAuD06dO2adfe3Hcj3333HfXr12fYsGHUqVOHypUrc/LkSdt8k8nE/fffz8aNG2+6naeffppVq1Yxd+5crFYr3bt3z9H+RQqS2v9/qf3PvL/8aP+vVapUKUqWLMm3336bafp3331HlSpVcHFxAS63uw0aNGDs2LHs2LGDevXqZbqPw9vbm86dO/PBBx+wc+dODh06ZPvjo7hSYXwbqlSpgtVqZdq0aZw8eZKVK1fyzjvv2CWLv78/Tz31FKNGjWL9+vX88ssvvPjii5w8efKmVxHy6hiefPJJXFxc6N27N4cPH2bHjh0MGjQoRzd11a1bl5CQEJ588kkSExMzFUJ33303Li4uzJgxg19//ZVNmzbx4osv5ipb9erVadmyJU8//TTfffcdkZGR9OnTJ1OjXapUKfz8/Jg7dy7Hjx9nx44d9OrVy3bnMVxuYCpUqMCWLVs4c+bMDT/yeu655zh79iz9+/cnMjKSb7/9lqeeeorw8HDq1q2bq+xXy0nGiIgI6tWrR+fOnfnmm284efIk33//PYsWLQKwjUbRvn17tmzZwsmTJ/nvf/9rGxy/WrVqlClThtdee41ffvmFb7/9lpdeeilH+apWrcqPP/7I2rVrOXHiBJMnT+abb77JtMxrr73GqlWrePHFFzl8+DA///wzCxcuzHSXefPmzSlXrhyjRo2iZ8+eGs9VHJLa/3+p/f9XfrX/WXn55ZeZMmUKixYt4vjx43zwwQcsXLiQMWPGALBt2zYmTJjAnj17+OOPP9i0aRNRUVGEhIQA8M4777BkyRKioqL49ddfWbRoES4uLlSqVClPcxY2KoxvQ926dZk6dSrvv/8+ISEhzJw5k2nTptktz7Rp02jRogXdunWjQYMGpKWl0bNnz0w/3NfKq2Pw9vZm3bp1/Pnnn4SFhdGnTx9Gjx6Nn59fjtbv3bs3Bw8epH379pnWKVOmDB9//DFfffUVISEhjBkz5pbyffrpp9x7771ERETQrFkzqlatSps2bWzzXVxcWL58OUeOHKFGjRoMGDCAUaNGXTdo+/Tp09m+fTsVKlSw9bO7VtmyZdm4cSPHjx+nTp06PProo4SFhdmGO7tVOcno7OzMxo0bad68Of379+fee++lT58+xMXFAZffp++//55KlSrRtWtXqlWrxrBhw0hLSwPAzc2NZcuW8fvvv1OrVi2GDx/Ou+++m6N8zz77LF27duWJJ56gTp06HDp0iLFjx2Zapn379nz11Vd8++231K1blwYNGvD555/brm7A5V9A/fv359KlS+pGIQ5L7f+/1P7/K7/a/6yMGDGCV155hTfffJPQ0FCmT5/OtGnTePzxx4HLfzB99913tG/fnsqVKzNw4ED69evHqFGjAPDy8uK9996jfv363HfffWzYsIEvv/ySu+++O8+zFiYmI6cdcKRQatiwIXfffbdt+BaRwmDYsGH88MMP7N27195RRAottf8iuVfsn3xXlBw4cIDIyEjq169PamoqH330ET/88APjx4+3dzSRHImPj+fAgQMsWrSI+fPn2zuOSKGh9l8kb6gwLmJmzJjBzz//DFzuL7p27VqaNm1q51QiOdOqVSsOHTrEE088oZvuRHJJ7b/I7VNXChERERERdPOdiIiIiAigwlhEREREBFBhLCIiIiIC2Pnmu6ufrpVTQUFBuX7yTX5wlBygLI6cAxwni6PkgMKfpUyZMvmUxrEV5jYbHCeLo+QAx8niKDlAWRw5B9x6lpy227piLCIiIiKCCmMREREREUCFsYiIiIgIoMJYRERERARQYSwiIiIiAqgwFhEREREBVBiLiIiIiAAqjEVEREREABXGIiIiIiKAnZ98J7mTng7x8U5cuGDiwgWnf752wmx2IjHR097xAPDycowsjpIDHCeLo+QAx8rSti34+dk7RdFkjorCFB0NDz9s7ygiIjmiwriAGQYkJpoyFbhX/l2ZFh/vRFzc9dMSE292gd+RfrM7ShZHyQGOk8VRcoCjZClVykKLFvZOUTR5zZqFy5df4vP00ySMGQNm/coREcemVuoWXboE589fKWpN1xS3TsTHZy56r0yLj3fCYjHdcLuurgZ+flb8/Kz4+lopUyaDatWstmmX/xn4+v77ukwZf+LiYgvw6G8sICCA2Fj7Z3GUHOA4WRwlBzhWlooVA0hOtneKounC1Km4lS6N19y5uPz0E3Effoi1VCl7xxIRuaFiXRgbBly8+G+3hLg40zXFbVZXdS+/Tk52AoJvuO0rheuV/++8M+Oa4taKr2/mItjf38Dd3cB047o5S0FB4O5uvb2TkUeCgsDNzf5ZHCUHOE4WR8kBjpXF0xMVxvnFzY2MGTNICA3F96WXKNmqFXFz5nCpfn17JxMRyVKRKIzT0shU0GZ1BfdKd4R/i9zLr63WG1eh7u5GpuK2XDkLNWoY/1yldcfFJRE/v8zFrZ+fFR8fA2fnAjwBIiIOLKVzZ9KrVSNgwAACu3YlYexYkgYMINdXAURE8lmhKozfftuHv/4yc+5c4FX9cE2kpt64763JZGS6MuvnZ6V8ect13RGuFLhXX+n18LhxlqAgV6KjdZlJRCQnLCEhnF+/Hr/hw/F9801cf/yRC5MnY3h52TuaiIhNoSqMIyPNxMaCtzdUqGDhvvuy7o5wdcHr7W3gpEHpRETszvDxIW7BAtI//BDviRMJOnqUuAULsFSubO9oIiJAISuMlyyJJSgoiOjoGHtHERGRW+HkROKQIVy67z78Bw8mqG1bLkyeTOojj9g7mYiIHvAhIiIF71KjRpzfsAFL1aoEPPMMPq+/fnmwdhEROypUV4xFROSy2bNn8+OPP+Lr68uUKVOum//VV1/x/fffA2C1Wvnzzz9ZuHAhXl5eDBkyBHd3d5ycnHB2dmbixIkFHf9yrjJliF65Ep+33sJrwQJcDh0ibs4crKVL2yWPiDg21717oU4d8rOPrApjEZFCqEmTJkRERDBr1qws5z/yyCM88k/3hH379rF27Vq8rrrR7fXXX8fHx6dAst6UqysJb71Feu3a+L744r9DujVoYO9kIuJA3P77XwKefhprhw4wbVq+7UddKURECqGQkJBMhe7N7NixgwcffDCfE92elEcfJfqbbzC8vQns1o0Sc+ZcHmxeRIo99zVrCOjfn/SqVcnIx6IYVBiLiBRpaWlpHDx4kAbXXIEdP348o0aNYvPmzXZKdj3Lvfdyft06Ulu2xPett/AfOBDTxYv2jiUiduT52Wf4DxnCpTp1iFm27PITovKRulKIiBRh+/fvp2rVqpmuLr/11lsEBAQQHx/P22+/TZkyZQgJCblu3c2bN9sK54kTJxJ0C7+QzGZz7tYLCoLVq7FMnYr72LEEnziBZdkyjCzy5XuWfOIoOcBxsjhKDlAWR8rhNHUq5tGjsbZsiWnZMgI9PfM9iwpjEZEibMeOHTRq1CjTtICAAAB8fX2pW7cuJ06cyLIwDg8PJzw83PY6Ojo61/u/PMRm7tfjySdxrVwZ/2eewfnBBy8P6dahQ+63kxdZ8pij5ADHyeIoOUBZHCKHYeA9aRLe779PSrt2xM2cCcnJkJx8y1nKlCmTo+XUlUJEpIhKTk4mKiqKsLAw27TU1FRSUlJsXx86dIjy5cvbK+JNXWrYkPMbN2IJCSFg8GB8XnsNLl2ydywRyU9WKz6vvYb3+++T1KMHcbNng6trge1eV4xFRAqh6dOnExUVxcWLFxk0aBDdunXDYrEA0LJlSwD27NnDfffdh7u7u229+Ph4Jk+eDEBGRgaNGjWiVq1aBX8AOWQNDiZ6xYrLQ7otXIjrTz8RO2cO1jvusHc0EclrFgt+L76I5xdfkDhgAAmvvw4mU4FGUGEsIlIIDR8+PNtlmjRpQpMmTTJNK126NJMmTcqnVPnExYWEceO4VKcOfiNHUjIigrgPP+RSw4b2TiYieSUtDf+hQ/FYt46EF14gccSIAi+KQV0pRESkkEjt0IHob77B6utL4GOPUeLDDzWkm0gRYEpOJuCpp/BYt474N94g8fnn7VIUgwpjEREpRCxVqxK9di2prVrh+/bb+A8YgCkhwd6xROQWmeLjCejZE7fvvyduyhSSBgywax4VxiIiUqgY3t7EzZtH/Kuv4r5pEyXbtMH888/2jiUiueQUHU1Q1664HjxI3OzZpDz2mL0jqTAWEZFCyGQiadAgYr74AlNSEkHt2uGxerW9U4lIDjmdPk1gp044/+9/xH70Eant29s7EqDCWERECrFLDRpwfsMG0mvUwH/oUHzGjtWQbiIOzvnkSYIefRTns2eJ/fxz0po1s3ckGxXGIiJSqFlLlybmn+GdvBYtIqhLF5xOn7Z3LBHJgvnoUYI6dcKUlETM8uVcql/f3pEyUWEsIiKFn4sLCW+8QeyHH2I+epSSERG4bt9u71QichWXAwcI6tIFnJyIWbWK9Jo17R3pOiqMRUSkyEh95BGi163D6u9PYI8eeM2apSHdRByA644dBHbvjtXXl+jVq7FUqWLvSFlSYSwiIkWKpXLly0O6tWmDz4QJ+PfrpyHdROzIbdMmAnv1IuPOO4letYoMB30MPagwFhGRIsjw8iJuzhzi33gD9//7P0q2bo3p8GF7xxIpdjxWryagf3/S772X6JUrsQYH2zvSTakwFhGRoslkImnAAGKWL8eUkoL5oYfwWLnS3qlEig3PTz/F79lnuVSvHjHLlmEEBNg7UrZUGIuISJF2qV49zm/YgBEWhv+wYfiOHg1pafaOJVKkec2ejd/LL5PWrBkxn36K4e1t70g5osJYRESKPGupUljWrydx0CBKfPIJQZ074/TXX/aOJVL0GAbeEyfiM348KY88QuyCBeDhYe9UOabCWEREigcXFxJefZXYuXMxHzt2eUi3776zdyqRosNqxefVV/GeOZOknj2J++ADcHW1d6pcUWEsIiLFSmq7dpxftw5rUBCBjz+O14wZYLXaO5ZI4Wax4DdiBF6LFpH49NPEv/ceODvbO1WuqTAWEZFiJ6NSJaK/+YaU9u3xefddAvr2xRQfb+9YIoVTWhr+gwbhuWIFCSNHkvDqq2Ay2TvVLTHnZKGDBw+yaNEirFYrzZs3p2PHjpnmnz9/ng8//JCEhAS8vLx49tlnCQwMzJfAIiIiecEoUYILs2aRXqcOPuPGUbJNG2LnzcMSGmrvaCKFhik5Gf9+/XD/7jvix40jqV8/e0e6LdleMbZarSxcuJAxY8Ywbdo0duzYwZ9//plpmU8//ZSHH36YyZMn06VLFz7//PN8CywiIpJnTCaS+vUjZsUKTKmplHzkETy++MLeqUQKBVN8PIGPPYbb9u3ETZ1a6ItiyEFhfOLECYKDgyldujRms5mGDRuyd+/eTMv8+eef1KhRA4DQ0FD27duXP2lFRETywaW6dTm/YQOX7r8f/xEj8B01SkO6idyEU3Q0QV264HLoEHFz5pDSvbu9I+WJbLtSxMbGZuoWERgYyPHjxzMtU6FCBXbv3k2bNm3Ys2cPKSkpXLx4Ee9rxqzbvHkzmzdvBmDixIkEBQXlPrDZfEvr5TVHyQHK4sg5wHGyOEoOUBZxTNaSJYlZuhTvd9/Fe/ZsXI4cIW7ePDLuvNPe0UQcitNffxH02GM4nT5N7OLFpDVpYu9IeSbbwtgwjOumma7pUN2rVy8++ugjtm3bRrVq1QgICMA5izsRw8PDCQ8Pt72Ojo7OdeCgoKBbWi+vOUoOUBZHzgGOk8VRckDhz1KmTJl8SiN2ZzZz8ZVXSK9dG7/hwwlq1YoLs2aR1rixvZOJOATnX38l8LHHcEpIIHbJEi7Vq2fvSHkq28I4MDCQmJgY2+uYmBj8/f0zLRMQEMDIkSMBSE1NZffu3Xh6euZxVBERkYKR2ro156tUIWDgQAIef5yLI0eSOGwYOGkwJym+zFFRBPbsCRkZxCxfTvo/3WiLkmx/witWrMiZM2c4d+4cFouFnTt3EhYWlmmZhIQErP+MAbl69WqaNm2aP2lFREQKSEbFikR//TUpHTviM2kSAX36YLpwwd6xROzCZf9+grp0AWdnYlatKpJFMeTgirGzszN9+/Zl/PjxWK1WmjZtSrly5Vi2bBkVK1YkLCyMqKgoPv/8c0wmE9WqVaNfEbgrUURExPD05MLMmVyqUwffN9+kZOvWxM6fj6V6dXtHEykwpq1bCXzsMaylShGzdCkZ5crZO1K+ydE4xrVr16Z27dqZpnW/6u7DBg0a0KBBg7xNJiIi4ghMJpKfeor0GjUIePppSnbowIUJE4rMXfgiN+O+cSPmZ57BcvfdxHz+OdbSpe0dKV/lqDAWERHHMnv2bH788Ud8fX2ZMmXKdfMjIyN57733KFWqFAD169enS5cuQPYPbZKspYeFcX7jRvwHD8b/+edx3b+f+HHjwN3d3tFE8oXHqlX4DR+OUbs20YsWYVxzj1lRpMJYRKQQatKkCREREcyaNeuGy1SrVo2XX34507QrD20aO3YsgYGBjB49mrCwMMqWLZvfkYsEa1AQMZ9/jvekSXh/8AEuhw9fHtKtCH+0LMWT58cf4/vKK1xq0ADT119jFJNxvXV7rYhIIRQSEoKXl1eu18vJQ5skG2YzF0ePJvajjzCfPEnJiAjctm61dyqRPOP1wQf4jRlDWvPmxHz6KVzzXIqiTIWxiEgRdezYMV588UUmTJjAqVOngKwf2hQbG2uviIVaaqtWnF+3jow77iCgVy+8pk2Df0ZoEimUDAPvd97B5513SO7QgdgFC8DDw96pCpS6UoiIFEF33303s2fPxt3dnR9//JFJkyYxY8aMHD206Yqi9LRSyKcsQUEYO3diHTIEn8mT8Tp8GMvixRAQULA5bpGjZHGUHFCMs1itOA8fjvPcuWT064d55kyC/nlYW3E6JyqMRUSKoKsfslS7dm0WLlxIQkJCjh7adEVRelop5HOW997Ds3p1fF9/Had69YibP/+G47wWm3NSCHNAMc1iseA3YgSuq1aR+MwzJLzyCsTFFXyOHLjYng7FAAAgAElEQVTVLDl9Yqm6UoiIFEEXLlywXR0+ceIEVqsVb2/vHD20SW6ByUTyk08SvWoVJouFoA4d8FyyxN6pRLKXmor/wIF4rlpFwqhRl4viG3yKVBzoirGISCE0ffp0oqKiuHjxIoMGDaJbt25YLBYAWrZsya5du9i0aRPOzs64uroyfPhwTCbTDR/aJHkjvXbty0O6DRmC38iRuOzfT/zbb2tIN3FIpqQkAvr2xW37di68/TbJTz1l70h2p8JYRKQQGj58+E3nR0REEBERkeW8rB7aJHnHGhhIzH/+g/fkyXjPmIHLkSOXh3QrX97e0URsTBcuENirFy4HDxI3fTopXbvaO5JDUFcKERGRvObszMVRo4hZtAjz779TsnVr3P7v/+ydSgQAp/PnCerSxfZHm4rif6kwFhERySdpLVtyfv16MsqUIeDJJ/GePBkyMuwdS4ox57/+IujRR3H+7TdiP/6Y1Nat7R3JoagwFhERyUcZd91F9FdfkdKlC97TpmFu1w5zZKS9Y0kx5Py//xHYsSNOMTHELllC2sMP2zuSw1FhLCIiks8MDw8uTJvGhYkTMe3dS6mWLQno0weXAwfsHU2KCXNkJEGdOmFKSyN6+XIu1a1r70gOSYWxiIhIQTCZSO7Vi/Tjx0kYORLXvXsp2a4dAT164Lprl73TSRHmsm8fQV27gosL0atWYale3d6RHJYKYxERkYLk70/iiBGc3b2b+LFjcYmKIqhzZwI7dcLt228hi6cTitwq1+++I7BHD6z+/kR/+SUZlSrZO5JDU2EsIiJiB4aXF0nPPMPZXbuIf+stzH/8QWDPngS1bYv7xo1gtdo7ohRy7hs3Evjkk2RUqED06tVklC1r70gOT4WxiIiIPXl4kNS3L2d37ODCe+/hFBdHQN++lGzZEvc1azSKhdwSjxUr8B8wgPTQUKKXL8daqpS9IxUKKoxFREQcgZsbyY8/zrnvvyduxgxITydg8GBKNWmCxxdfQHq6vRNKIeG5eDH+zz3HpQYNiFm6FMPf396RCg0VxiIiIo7EbCalc2fOb91K7Ny5GO7u+I8YQamHHsLzk08gLc3eCcWBec2cid8rr5DaogUxn3yC4eVl70iFigpjERERR+TkRGq7dpzftImYxYuxBgXhN3o0pRs2pMT8+ZhSUuydUByJYeA9YQI+EyeS3KkTsfPng7u7vVMVOiqMRUREHJnJRFqLFkR//TXRS5diuftufN94g1L16+P1wQeYLl60d0KxN6sV39Gj8Z41i6Revbjw/vvg4mLvVIWSCmMREZHCwGTi0kMPEbNiBdGrV5NesyY+77xD6fr18Z4yBVNcnL0Tij2kp+M3bBglPv2Ui0OGEP/OO+Ck8u5W6cyJiIgUMpfq1SP2s884v24daQ88gPfUqZcL5PHjcTp/3t7xpKCkpuI/cCCeq1eTMHo0F8eMAZPJ3qkKNRXGIiIihVT6ffcRt3Ah5zZvJrVFC7zmzKF0gwb4vPYaTqdP2zue5CNTUhKBvXvjsWkTF8aPJ3HoUHtHKhJUGIuIiBRylmrVuDBrFue2bSOlQwdKfPwxpRs2xPell3D+/Xd7x5M8ZoqLI7B7d1x37SJuxgyS+/Sxd6QiQ4WxiIhIEZFRsSIXpk7l3PbtJPfogefy5ZR66CH8hg3DfPy4veNJHnA6d46grl1xiYwkbt48Ujp3tnekIkWFsYiISBGTUa4c8e+8w9kffiCpXz/c162jZNOm+D/9NObISHvHk1vk/OefBD36KM6//07MJ5+QGhFh70hFjgpjERGRIsoaHEzC669zbvduEocOxW3bNkq1bElAnz64/PijveNJLjifOEFQx444xcURs2QJlx56yN6RiiQVxiIiIkWcNTCQiy+/zNndu0kYORLXvXsp2b495jZtcN21y97xJBvmI0cI6tQJ0tOJXr6c9LAwe0cqslQYi4iIFBOGnx+JI0Zwds8e4l99FdORIwR17kzgo4/itm0bGIa9I8o1XPbuJahrVww3N6JXrcISGmrvSEWaCmMREZFixihRgqRBg0j/5RcuvP025lOnCHz8cYLatsV940awWu0dUQDT5s0E9uiBNTCQmC+/JKNiRXtHKvJUGIuIiBRXHh4kP/UUZ3fu5MKkSThduEBA376UbNEC9zVrICPD3gmLp4wM3L/6CvOjj5Jx111Er15Nxp132jtVsWC2dwARERGxM1dXknv2JLlbNzzWrMFr5kwCBg/GMnkyF4cOJaVTJ3BxsXfKIsmUnIz56FFcIiNxOXIEl6gozEeP4pSairVBA6IXLsTw87N3zGJDhbGIiIhcZjaT0rkzKY8+ivv69Xi//z7+zz+P99SpJA4ZQnK3buDubu+UhZbTuXOXC+B//pkjIzH/+iumf/p2W/38SA8JIblXL9KrV6dE794Yycl2Tl28qDAWERGRzJycSG3bltQ2bXD7v//D+/338Rs9Gu/33ydx0CCSH38cw9PT3ikdV0YG5pMnMV9VBLtERuJ8/rxtEUv58qSHhpLy6KOkh4ZiCQ0lo0wZMJlsy5Tw9AQVxgVKhbGISCE0e/ZsfvzxR3x9fZkyZcp187///nvWrFkDgLu7O/379+euu+4CYMiQIbi7u+Pk5ISzszMTJ04syOhSmJhMpIWHk9a8Oa47duD9/vv4vvEGXjNnkjRgAEl9+mB4e9s7pV1l6gpx5UrwP10hAAwXF9KrViWtWTPSQ0Mv/6tWDcPX187JJSsqjEVECqEmTZoQERHBrFmzspxfqlQp3njjDby8vDhw4ADz5s1jwoQJtvmvv/46Pj4+BRVXCjuTiUuNGhHTqBGue/fiNWMGPhMn4vXhhyT17Utiv34Y/v72Tpnvsu0K4etLemjo5a4Q/xTBlkqVwNXVzsklp1QYi4gUQiEhIZw7d+6G86tWrWr7unLlysTExBRELCkGLtWtS+ynn+Jy6BBeM2bgPW0aJebNI+nJJ0kaOBBryZL2jnj7ctIVoly5y10hOnbEEhpKevXq13WFkMJHhbGISBG3ZcsW7r///kzTxo8fD0CLFi0IDw/Pcr3NmzezefNmACZOnEhQUFCu9202m29pvfzgKFkcJQfcZpZmzaBZM9IjI3F691285szB66OPsPbtS8bzz0O5cgWT43YlJWE6cgTTTz9h+uknnA4f5o5DhzClpACXu0IYISEYrVtjqVkT4777MGrWBD8/nAHnfIzmKN8rjpID8j+LCmMRkSLsyJEjbN26lXHjxtmmvfXWWwQEBBAfH8/bb79NmTJlCAkJuW7d8PDwTEVzdHR0rvcfFBR0S+vlB0fJ4ig5II+ylC4NU6fiPHQoXrNm4TlvHk7z55PcrRuJQ4aQUaFCweTIgZx0hTBq1SL58cf/7QpRufL1XSEsFiiAvI7yveIoOeDWs5QpUyZHy6kwFhEpon7//Xfmzp3L6NGj8b7qBqmAgAAAfH19qVu3LidOnMiyMBbJjYx77iF+yhQSR4zAa/ZsPJcuxXPpUlI6diTx2WcvF5gFFiYD55MnLxfAUVGXxwfOritEaCgZd95JUMmSJDhIESgFT4WxiEgRFB0dzeTJkxk6dGimKyWpqakYhoGHhwepqakcOnSILl262DGpFDUZZcsSP2ECF597Dq+5c/H85BM8Vq0itW1bLj77LJbq1fN0f6aUlKxHhbiqK4SlShXSmjbNPCqEHpohWVBhLCJSCE2fPp2oqCguXrzIoEGD6NatGxaLBYCWLVuyYsUKEhMTWbBgAYBtWLb4+HgmT54MQEZGBo0aNaJWrVp2Ow4puqylS5Pw2mskDh1KifnzKbFoER7ffENqeDgXn3uO9Nq1c71Np/PnM3WDcLnSFcJqvbxPX9/LD8jIriuEyA3kqDA+ePAgixYtwmq10rx5czp27JhpfnR0NLNmzSIpKQmr1UrPnj2pfQvf8CIikjPDhw+/6fxBgwYxaNCg66aXLl2aSZMm5VcsketYAwK4OGoUiYMGUWLRIrzmz6dk+/akPfQQF597jksNGly/0rVdIa6MCnHVSCy2rhAdOmTqCqFRIeR2ZFsYW61WFi5cyNixYwkMDGT06NGEhYVRtmxZ2zIrV67kgQceoGXLlvz555+88847KoxFRETExvD1JXH4cJIGDMDz00/xmjOHoC5dSKtXD6fnnsPz1Kmsu0KYzZe7QjRu/G9XiJAQdYWQfJFtYXzixAmCg4MpXbo0AA0bNmTv3r2ZCmOTyUTyP48sTE5Oxr8YDPItIiIiuWeUKEHSoEEkPfkknsuW4TVrFubHH8cPsPr4XH5ARs+embtCuLnZO7YUE9kWxrGxsQQGBtpeBwYGcvz48UzLdO3albfffpsNGzaQlpbGq6++mvdJRUREpOjw8CC5Tx+Se/ak5IkTxHp7k1G2rLpCiF1lWxgb/4ztdzXTNd+0O3bsoEmTJrRv355jx44xc+ZMpkyZgpOTU6blitJg8Y6SA5TFkXOA42RxlBygLCJyFVdXjIcfJkNDpIkDyLYwDgwMzPQo0ZiYmOu6SmzZsoUxY8YAUKVKFdLT07l48SK+vr6ZlitKg8U7Sg5QFkfOAY6TxVFyQOHPktOB4kVEpHBxym6BihUrcubMGc6dO4fFYmHnzp2EhYVlWiYoKIgjR44A8Oeff5Keno6Pj0/+JBYRERERyQfZXjF2dnamb9++jB8/HqvVStOmTSlXrhzLli2jYsWKhIWF0bt3b+bOncvatWsBGDx48HXdLUREREREHFmOxjGuXbv2dcOvde/e3fZ12bJleeutt/I2mYiIiIhIAcq2K4WIiIiISHGgwlhEREREBBXGIiIiIiKACmMREREREUCFsYiIiIgIoMJYRERERARQYSwiIiIiAqgwFhEREREBVBiLiIiIiAAqjEVEREREABXGIiIiIiKACmMREREREUCFsYiIiIgIAGZ7BxAprgzDIDU1FavVislkyvf9nT17lrS0tHzfT04UhiyGYeDk5IS7u3uBvD8i4pgKuq2+mqO0lY6SA26eJS/abRXGInaSmpqKi4sLZnPB/BiazWacnZ0LZF/ZKSxZLBYLqampeHh4FHAqEXEUBd1WX81R2kpHyQHZZ7nddltdKUTsxGq12qWhlZwzm81YrVZ7xxARO1JbXbjcbrutwljETvTxfOGg90mkeFMbUPjcznumP4FERAqh2bNn8+OPP+Lr68uUKVOum28YBosWLeLAgQO4ubkxePBg7rnnHgC2bdvGqlWrAOjUqRNNmjQpyOgiIg5LV4xFiqnY2FhatGhBixYtqFWrFnXq1LG9vnTpUo62MWLECE6cOHHTZRYvXmwrwiTvNGnShDFjxtxw/oEDB/j777+ZMWMGAwcOZMGCBQAkJiayYsUKJkyYwIQJE1ixYgWJiYkFFVtEcqkwttUdO3bkyJEjebKtgqYrxiLFVEBAAP/9738BmDJlCiVKlGDQoEGZljEMw3aXb1amTZuW7X769Olz21nleiEhIZw7d+6G8/ft28fDDz+MyWSiSpUqJCUlERcXR2RkJDVr1sTLywuAmjVrcvDgQRo1alRQ0UUkF9RWFyxdMRaRTE6ePEmzZs0YNWoUrVq14uzZs7z00ku0bt2apk2bZmpgr1wVsFgsVKtWjQkTJhAeHk779u2Jjo4G4N1332X+/Pm25SdMmECrVq146KGH2Lt3LwDJyckMGDCA8PBwBg8eTOvWrbO82jB58mTatGljy2cYBgD/+9//6Nq1K+Hh4bRq1YpTp04BMGPGDJo3b054eDgTJ07M1/PmaGJjYwkKCrK9DgwMJDY2ltjYWAIDA23TAwICiI2NtUdEEbkNBdFWt23b9pba6qutXLmS5s2b06xZM9555x3g8sgRzz77rG36woULAZg3bx5NmjQhPDycZ599Ns/PWU7oirGIA3jtNR+iolzydJshIemMG5dwS+seO3aMqVOn8u677wIwevRo/P39sVgsdO3albZt21KlSpVM6yQkJNCgQQPGjBnDG2+8wdKlSxk6dOh12zYMg40bN7Ju3TqmT5/Of/7zHz766CNKlizJ/PnziYyMJCIiIstc/fr1Y+TIkRiGwZAhQ9i6dSvNmjVjyJAhPP/887Rs2ZLU1FQMw2DTpk1s3bqVb775Bg8PD+Li4m7pXBRWV/5ouNqNbki50fTNmzezefNmACZOnJip0M4ps9l8S+vlB0fJ4ig5wHGyOEoOuD7L2bNnbaNSjB3rRWRk3pZOoaEW3n77xt2Zrh4Rw8nJCScnJ8xmM2azmWPHjvH+++/b7jN49dVXbW11p06deOSRR6hatSomk8m2TkJCAg8++CCvvfYar732Gl988QXDhg3LtG2TyYTJZGLjxo1s2LCBKVOmsHTpUhYvXkzp0qVZtGgRkZGRhIeH27Z7tSv7O3fuHJMmTWLjxo34+PjQtWtXtmzZQmBgIBcuXODbb78FID4+HrPZzIcffsj+/ftxdXW1TcvunGTFzc3tlr+fVBiLyHUqVKhArVq1bK/XrFnDkiVLyMjI4O+//+bYsWPXFcbu7u40a9YMuPzx/O7du7PcduvWrQGoUaOG7crunj17GDJkCAChoaFUrVo1y3W3b9/OnDlzSEtLIzY2lpo1a1K7dm1iY2Np2bKlLceVZR977DHbWJb+/v63dC4Kq8DAQNuVIICYmBj8/f0JCAggKirKNj02NpaQkJAstxEeHk54eLjt9dXby6mgoKBbWi8/OEoWR8kBjpPFUXLA9VnS0tJs4+ZardYs/+i8HVarFYvFkuU8s9mcaZ7VarUtb7FYqFChAjVq1LAts3Llykxt9dGjR6lYsSKGYdjWcXd3p3HjxlgsFqpXr87u3buxWCyZtm0YBq1atcJisRAaGsqpU6ewWCzs2rWLIUOGYLFYqFq1KlWrVrVt92pX9rd3714aNmyIr68vAB06dGDnzp0MHjyYEydOMGbMGJo1a2bLU6VKFZ555hlatWpFRERElufl2nOSlbS0tOu+n8qUKZP9m4EKYxGHcKtXdvOLp6en7etff/2VBQsWsHbtWnx9fXn22WezfOqQq6ur7WtnZ2cyMjKy3PaV5a5eJie/aFJSUhg7diwbNmzgjjvu4N133yU1NRXI+opnXv/yKmzCwsLYsGEDDz74IMePH8fT0xN/f39q1arFkiVLbDfc/fTTT/Ts2dPOaUUKh+LaVl8pRHPbrt5o+YCAADZv3syWLVtYuHAh69at47333uPzzz/nhx9+YNOmTbz//vts2bKlwB8soj7GInJTiYmJeHl54e3tzdmzZ9m2bVue76NevXp8/fXXABw9epRjx45dt0xKSgpOTk4EBASQmJjIunXrAPDz8yMgIIBNmzYBl59SlZKSwsMPP8zSpUtJSUkBKHJdKaZPn87YsWM5ffo0gwYNYsuWLWzatMl2Hu6//35KlSrFsGHDmDt3Lv379wfAy8uLzp07M3r0aEaPHk2XLl1sN+KJSOHlKG311WrXrs3OnTuJjY3FYrGwZs0aGjRoQExMDIZh0L59e0aOHMnhw4fJyMjgzJkzNGrUiLFjxxITE2NrvwuSrhiLyE3VqFGDypUr06xZM8qXL0/dunXzfB99+/blueeeIzw8nOrVq1O1alV8fHwyLRMQEEDXrl1p1qwZZcuW5f7777fNmzlzJi+//DLvvfceLi4uzJ8/nxYtWhAVFUWbNm0wm820aNGCl156Kc+z28vw4cNvOt9kMtmK4Ws1a9bM1u1FRIoGR2mrr1amTBlGjhxJ165dMQyDFi1aEB4ezuHDh3nhhRcwDAOTycQrr7yCxWJhyJAhJCUlYbVaGTJkiF3+aDcZdvy88fTp07lex1H6ITlKDlAWR84BN86SnJyc6WOw/JaTflkF5dosV/d9+/XXX+nZsyfbt28vkMewZndesnqfctpXragpzG02OE4WR8kBjpPFUXLA9VkKuq2+mqO021dy2LOtvjbLzdxOu60rxiJid0lJSXTv3t3W2L377rsF2tCKiEj2ikNbXbSORkQKJV9fXzZs2GDvGCIichPFoa3WzXciIiIiIqgwFhEREREBVBiLiIiIiAAqjEVEREREABXGIsVWly5drhsAfv78+YwePfqm61WuXBmAv//+mwEDBtxw2z/99NNNtzN//vxMg7f36tWL+Pj4HCQXESk+HKGtTk5Otr3Oq7Z6ypQpzJkz57a3k9dUGIsUUx06dGDNmjWZpq1Zs4aOHTvmaP3g4GDmz59/y/tfsGBBpsL4008/xdfX95a3JyJSFKmtLlgqjEWKqbZt27J582bS0tIAOHXqFGfPnqVevXokJSXRrVs3WrVqRfPmzdm4ceN16586dcr29LSUlBSeeeYZwsPDGTRoEKmpqbblXn75ZVq3bk3Tpk2ZPHkycPkKxNmzZ+natStdunQBoH79+sTGxgIwd+5c29PZrjTop06donHjxrz44os0bdqUHj16ZPm40E2bNtGuXTtatmxJ9+7dOX/+PHB5/M0RI0bQvHlzwsPDWbt2LQBbtmyhVatWhIeH061btzw5tyIiecWebfXChQs5e/YsnTp1yvO2+mpHjhyhXbt2hIeH069fPy5cuGDbf5MmTQgPD+eZZ54BYOfOnbRo0YIWLVrQsmVLEhMTb/ncZkXjGIs4AJ/XXsMlKipPt5keEkLCuHE3nB8QEECtWrXYtm0brVq1Ys2aNTzyyCOYTCbc3NxYuHAh3t7exMbG0r59e1q2bInJZMpyW5988gkeHh5s3ryZqKgoIiIibPNGjRqFv78/GRkZdO/enaioKAYMGMCcOXNYvnw5AQEBmbZ16NAhvvjiC7755hsMw6Bdu3Y88MAD+Pr6cvLkSWbNmsWkSZN4+umnWbduHZ07d860fr169fj6668xmUx8/vnnzJ49m9dff53p06fj7e3N//3f/wFw4cIFYmJieOGFF1i5ciXly5cnLi7uVk+3iBQDxa2t7tevH/PmzWPVqlXXXSW+3bb6asOHD+ett97igQceYNKkSUydOpVx48Yxa9YsfvjhB9zc3GzdN2bPns2ECROoW7cuSUlJuLm55eZ0Z0tXjEWKsY4dO9o+orv6oznDMJg4cSLh4eF0796dv//+23blNSu7d++mU6dOAISEhFCtWjXbvK+//ppWrVrRqlUrfvnlF44fP37TTHv27CEiIgJPT09KlChB69at2b17NwDlypWjevXqANSsWZNTp05dt/6ZM2fo2bMnzZs358MPP+TYsWMAfP/99/Tp08e2nJ+fH/v376dBgwaUL18eAH9//5tmExGxh6LYVl+RkJBAfHw8DzzwAABdu3a1badatWoMHTqUlStX2p6wV69ePd58800WLlxIfHx8nj95T1eMRRzAza4W5KeIiAjefPNNDh8+TGpqKjVq1ABg1apVxMTEsH79elxcXKhfv77tY7wbyeoKxR9//MHcuXNZu3Ytfn5+DB8+PNNHd1kxDOOG866+MuDs7Jzltl599VUGDhxIy5Yt2blzJ1OnTrVtN6uMN7qyIiJyLbXV/7rdtjonPvnkE3bt2sWmTZuYPn06W7duZdiwYTRt2pQtW7bQvn17li1bRqVKlW5p+1nRFWORYqxEiRI88MADPP/885lu5Lh48SJBQUG4uLiwY8cO/vzzz5tup379+qxevRqAn3/+maNHj9q24+HhgY+PD+fPn2fr1q22dby8vLLsG9agQQM2btxISkoKycnJbNiwgfr16+f4mBISEggODgZg+fLltumNGzdm0aJFttcXLlygTp06/PDDD/zxxx8A6kohIg6pKLbVV/j4+ODr62u7Srxy5UoaNGiA1Wrl9OnTPPjgg4wdO5aEhASSkpL47bffqFatGkOGDOG+++7jxIkTud7nzeiKsUgx17FjR/r378+HH35om9apUyeefPJJWrduTWhoaLZ/jffu3Zvnn3+e8PBwQkJCqFWrFgChoaFUr16dpk2bUr58eerWrWtb5/HHH+eJJ56gVKlSrFixwja9Ro0adO3albZt2wLQo0cPqlevftOP4q72wgsv8PTTTxMcHEzt2rVt6z333HOMGTOGZs2a4eTkxPPPP0+bNm2YPHky/fv3x2q1EhQUxNKlS3N24kRECpA92+qePXtSsmTJPG2rrzZ9+nRefvllUlNTKV++PFOnTiUjI4Nnn32WixcvYhgGAwYMwNfXl8mTJ7Njxw6cnJyoUqUKTZs2zfX+bsZk3OxaeD47ffp0rtcJCgoiOjo6H9IUzhygLI6cA26cJTk5GU9PzwLLYTabsVgsBba/mylMWbJ6n8qUKZPfsRxSYW6zwXGyOEoOcJwsjpIDrs9S0G311RylrXSUHJCzLLfTbqsrhYiIiIgIKoxFRERERIAc9jE+ePAgixYtwmq10rx58+uetrJ48WIiIyMBuHTpEvHx8SxevDjPw4oUJXbsxSS5oPdJpHhTG1D43M57lm1hbLVaWbhwIWPHjiUwMJDRo0cTFhZG2bJlbctcPTbo+vXrOXny5C0HEikunJycsFgseT4Go+Qdi8WCk5M+WBMpztRWFy63225n+y6fOHGC4OBgSpcuDUDDhg3Zu3dvpsL4ajt27NBjVUVywN3dndTUVNLS0gpkLF03N7dsx7csKIUhi2EYODk54e7ubodUIuIoCrqtvpqjtJWOkgNuniUv2u1sC+PY2FgCAwNtrwMDA2/4NJTz589z7tw529NOROTGTCYTHh4eBbY/R77r254cKYuIOJ6Cbquv5ijtk6PkgPzPkm1hnFU/jRv9xbRjxw4aNGhww0vYmzdvZvPmzQBMnDiRoKCg3GQFLg/TcSvr5TVHyQHK4sg5wHGyOEoOUBYREXFM2RbGgYGBxMTE2F7HxMTg7++f5bI7d+6kX79+N9xWeHg44eHhtte3UvE7yl8tjpIDlMWRc4DjZHGUHFD4sxTXcYxFRIq6bHsnV6xYkTNnznDu3DksFgs7d+4kLCzsuuVOnz5NUlISVapUyZegIlyDGCcAABx2SURBVCIiIiL5Kdsrxs7OzvTt25fx48djtVpp2rQp5cqVY9myZVSsWNFWJG/fvp2GDRsWeMd0EZHi6naG0uzevTvly5cHLl81HzVqVIFmFxFxRDkae6R27drUrl0707Tu3btneq2RKERECs7tDqXp6urKpEmTCjKyiIjD0wCdIiKF0NVDaZrNZttQmjeyY8cOGjVqVIAJRUQKH41WLSJSCN3uUJrp6em8/PLLODs706FDB+rVq5fvmUVEHJ0KYxGRQuh2h9KcPXs2AQEBnD17lnHjxlG+fHmCg4MzrVeUhtgEx8niKDnAcbI4Sg5QFkfOAfmfRYWxiEghdLtDaQYEBABQunRpQkJC+O23364rjIvSEJvgOFkcJQc4ThZHyQHK4sg54Naz5HSYTfUxFhEphG5nKM3ExETS09MBSEhI4Jdffsl0056ISHGlK8YiIoXQ7Qyl+ddffzFv3jycnJywWq107NhRhbGICCqMRUQKrVsdSrNq1apMmTIlX7OJiBRG6kohIiIiIoIKYxERERERQIWxiIiIiAigwlhEREREBFBhLCIiIiICqDAWEREREQFUGIuIiIiIACqMRUREREQAFcYiIiIiIvD/7d17cFRlnsbxb3fnnk5iuhsSrqMGtArUiUmrgJcViMKOuhPxwk5KF0dqZx0cEZlViQqhVMrsAErNgHdgapEqWV3B1VEniwzjjlmQCMFBKCTirLcIdDfkHkhyzv4R0tgkIQ2mu0+H51NF5fQ5b9NPv5A3v7z9nnNQYSwiIiIiAqgwFhEREREBVBiLiIiIiAAqjEVEREREABXGIiIiIiKACmMREREREUCFsYiIiIgIoMJYRERERARQYSwiIiIiAqgwFhEREREBVBiLiIiIiAAqjEVEREREABXGIiIiIiKACmMREREREUCFsYiIiIgIoMJYRERERARQYSwiIiIiAkBCrAOIiMiZqa6uZvXq1RiGweTJkykuLg45vnnzZtasWYPL5QJg6tSpTJ48OXjsjTfeAGDatGlce+21Uc0uImJFKoxFROKQYRisXLmSxx57DLfbTWlpKV6vl+HDh4e0mzBhAjNnzgzZ19jYyOuvv055eTkA8+bNw+v14nQ6o5ZfRMSKtJRCRCQO1dTUkJubS05ODgkJCUyYMIFt27aF9dzq6mouueQSnE4nTqeTSy65hOrq6ggnFhGxPs0Yi4jEoUAggNvtDj52u93s27evW7utW7eyZ88ehgwZwowZM/B4PN2e63K5CAQCUcktImJlKoxFROKQaZrd9tlstpDHhYWFXHnllSQmJlJRUcGKFSsoKyvr8e87+bkAGzduZOPGjQCUl5fj8XhOO2dCQsIZPS8SrJLFKjnAOlmskgOUxco5IPJZVBiLiMQht9uN3+8PPvb7/WRnZ4e0ycjICG4XFRWxdu1aoHOGePfu3cFjgUCAMWPGdHuNoqIiioqKgo99Pt9p5/R4PGf0vEiwShar5ADrZLFKDlAWK+eAM88ydOjQsNppjbGISBzKy8ujtraWgwcP0t7eTmVlJV6vN6TN4cOHg9tVVVXBE/Py8/PZuXMnjY2NNDY2snPnTvLz86OaX0TEijRjLCIShxwOB3fffTeLFi3CMAwmTpzIiBEjWLduHXl5eXi9Xt59912qqqpwOBw4nU5mzZoFgNPp5JZbbqG0tBSAW2+9VVekEBFBhbGISNwqKCigoKAgZN/06dOD2yUlJZSUlPT43EmTJjFp0qSI5hMRiTdaSiEiIiIiggpjEREREREgzKUUfd12FKCyspLXXnsNm83Gj370I+6///5+DysiIiIiEil9Fsbh3Ha0traWDRs28MQTT+B0Oqmrq4toaBERERGR/tbnUopwbjv6/vvvM2XKlOBZzVlZWZFJKyIiIiISIX3OGIdz29Fvv/0WgPnz52MYBrfddpuuiSkiIiIicaXPwjic244ahkFtbS1lZWUEAgEWLFjA0qVLSU9PD2k3kG4vapUcoCxWzgHWyWKVHKAsIiJiTX0WxuHcdtTlcnHBBReQkJDA4MGDGTp0KLW1tYwaNSqk3UC6vahVcoCyWDkHWCeLVXJA/GcJ99aiIiISX/pcYxzObUcvv/xydu3aBUB9fT21tbXk5OREJrGIiIiISAT0OWMczm1Hf/zjH7Nz504eeOAB7HY7d9xxBxkZGdHILyIiIiLSL8K6jnFftx212WzMmDGDGTNm9G86EREREZEo0Z3vRERERERQYSwiIiIiAqgwFhEREREBVBiLiIiIiAAqjEVEREREABXGIiIiIiKACmMREREREUCFsYiIiIgIoMJYREQipKYmgT17Yp1CRCR8KoxFRCQili1zkp+fxPXXD+K559L55hv9yBERa9MoJSIiEbFgQT1Ll7aTlGTy5JNZXH55Lrfc4ubf/z2NQEA/fkTEejQyiYhIRAwebPCrXxm8/baPDz88wEMP1eP32yktPYdLL83hn/7JxRtvpNLUZIt1VBERABJiHUBERAa+c8/t4P77G5k9u5HduxPYsCGVDRtSef/9bFJSDKZMaaW4uIVrrz1KUlKs04rI2UqFsYiIRI3NBmPHtjN2bAOlpQ1UVSWxfn0qb72VwptvpnHOOQY33NBCcXEL48Ydw67PNUUkilQYi4jEqerqalavXo1hGEyePJni4uKQ42+//Tbvv/8+DoeDzMxMfvnLXzJo0CAApk+fzsiRIwHweDw8/PDDUc9vt8Pllx/j8suP8fjjdfzP/ySzfn0q69ensnZtOrm5HfzDP7Rw880tXHxxGzatuBCRCFNhLCIShwzDYOXKlTz22GO43W5KS0vxer0MHz482Obcc8+lvLyc5ORkKioqeOWVV3jggQcASEpKYvHixbGK301iIkyadJRJk47S0mKjoiKZN99MZfXqdF580cn557dTXNxCcXEzeXkdsY4rIgOUPqQSEYlDNTU15ObmkpOTQ0JCAhMmTGDbtm0hbS666CKSk5MBGD16NIFAIBZRT1tqqslPf9rKqlWHqa7+jsWLj5Cb28Ezzzi55poc/v7vPbzwQjq1tfoRJiL9S6OKiEgcCgQCuN3u4GO3233KwnfTpk3k5+cHH7e1tTFv3jweffRRPvroo4hm/SHOOcekpKSZ117zs23bAcrK6rDZ4PHHs7jsshxuvdXN2rVpHD6sdRYi8sNpKYWISBwyTbPbPlsvi3A/+OAD9u/fz8KFC4P7nn32WVwuFwcOHODxxx9n5MiR5Obmhjxv48aNbNy4EYDy8nI8Hs9p50xISDij5/XE44GLL4ZHHoF9+47xH/9h59VXk3jooWQefTSL6683+cd/NLjhBoP09Mhm+SGskgOsk8UqOUBZrJwDIp9FhbGISBxyu934/f7gY7/fT3Z2drd2n3zyCevXr2fhwoUkJiYG97tcLgBycnIYM2YMf/vb37oVxkVFRRQVFQUf+3y+087p8XjO6Hl9yc6Gf/kX+MUvYNeuRNavT+XNN1P5wx8SSEszmDq1lZ/+tIW/+7ujdL3tSGU5XVbJAdbJYpUcoCxWzgFnnmXo0KFhtdNSChGROJSXl0dtbS0HDx6kvb2dyspKvF5vSJsvvviCl156iYceeoisrKzg/sbGRtra2gCor69n7969ISftxRObDS6+uI0FC+rZtu0Ar7/u4+abW9i0KYUZM9xcemkO8+ZlsWVLEoYR67QiYnWaMRYRiUMOh4O7776bRYsWYRgGEydOZMSIEaxbt468vDy8Xi+vvPIKra2tPP3008CJy7J98803vPjii9jtdgzDoLi4OG4L4++z22H8+GOMH3+MJ5+s489/TmbDhlRefz2VNWvSGT7c5KabMikubmbs2HZd/k1EulFhLCISpwoKCigoKAjZN3369OD2/Pnze3zehRdeyNKlSyOaLdaSkuC6645y3XVHaW62UVGRwh/+kMVLL6Xz3HNORo1qO375txbOO0+XfxORTlpKISIiA1pamklxcQvr17ezY8d3lJcfYdAggyVLMrnqqhxuvNHDyy+nc+CAfiSKnO00CoiIyFnD5TK5885mXn/dz0cffcf8+XW0tUFZWRZebw7Tp7t59dVU6uq0zkLkbKTCWEREzkrDhhncc08Tf/yjjz//+SD339/I1187+PWvs8nPz2XmzGzeeiuFlpZYJxWRaNEaYxEROeuNGtXOv/5rA7/+dQM7dyayYUMq//Vfqbz3Xirp6Z2Xf7v55hauvvooCfrJKTJg6dtbRETkOJsN8vPbyM9vY/78ev73f5PYsCGVd95J5T//Mw23u4ObbmqluLiFwsJj2PW5q8iAom9pERGRHjgccNVVx1iypI4dO75j1aoAEyYc49VXUyku9jB+/GCeeiqDPXs0xyQyUOi7WUREpA/JyTBlSitTprTS2Gjjj39MYcOGVJ57zsny5RlceOGJy7+NHKnLv4nEK80Yi4iInAan0+SWW1pYsybAjh0HWLToCFlZBv/2b5mMH5/DTTd5WLUqnUOH9CNWJN7ou1ZEROQMud0Gd93VzPr1frZuPcAjj9TT2mpj/vwsCgpyKClxsW5dKvX1uvybSDxQYSwiItIPhg/v4N57G/nv/z7Epk0H+dWvGvniiwTmzu28/Ns//3M277yTQmtrrJOKSG+0xlhERKSfXXhhOw8/3MBDDzWwY8eJy7+9804q99xjkpmZQ1aWSWamQUaGSVZW59fMTCNkOzOz6+uJ7YwME4cj1u9QZGBSYSwiIhIhNhsUFLRRUNDGggX1VFYmU119DrW1rTQ02Kirs1Nfb+fzzxOoq7PT0GCjqanvD3OdTuOkwvnE14yMzuL6xHbn186iu3M7JSUKb14kDqkwFhERiYKEBLjmmqNMm9aBz1fXa7v2dqivt9HQ0Fk019fbTvrafd9339nZty/heKFtwzBOvaY5ObmzQM7OtuN0eo4Xzj3PUncV198/lp5u6hrOMiCpMBYREbGQhARwuUxcrg7g9C/9ZprQ3Gyjru5Ecd21fWJf52z1sWMpHDpkUFdn59tvTxTbra2nrnptNjNkaUfn8o/OwrmvpSBdxXZS0hl2kEgEqTAWEREZQGw2SE83SU83AeOUbT2eRHy+QLf9R48SLKB7m63+/lKQhgYbX32VQEPDiWOmeepZ69TUE8Wy2+0gKysbj8fA4zEYNKjj+FcDj6eDQYM629p0cQ+JMBXGIiIiEiI5GZKTDTweOJNZa8OAxsaTi+rei+vmZgdffpnAxx/bCQTsPS4FSUoycbtDi+au7c4/Hcf3GWRnG1rqIWdEhbGIiIj0K7ud47PB4RXVHo8Hn88HQEcHBAJ2Dh2y4/PZ8fkcwe1DhxzHv9rZvTsRv99OW1v3Itrh6Cyiuwrmkwvprploj8fA7TZITOzXty9xTIWxiIiIWIbDQXDmty+mCUeO2EKK554K6f37E/D5HLS29rwWIzu743ixbDBsmIPMzMxuSzkGDTJwuzt0RY8BToWxiIiIxCWbDbKzTbKz2xk9+tRtTROammzHi+bO4vnQITt+f+hM9Pbtdg4cSKOxsee1GBkZPa+D7qmQ7lznLfFEhbGIiIgMeDYbOJ0mTmcH553X+xKPrmUdLS3g958ooLuK6a5C+tChzkvkVVY6OHKk5yI6NdUIOaGwa1Z60KCO4+ulTxTTWVk6udAKVBiLiIiInCQ1tfM238OH971Ouq0NfL7Qojl0eYedr75KYMeOzjanOrmwa8bZ4zEYPNiB3Z5BerqJ02mQlmYGrziSnm6SlmbgdJ54nJKi4vqHCqswrq6uZvXq1RiGweTJkykuLg45vnnzZtasWYPL5QJg6tSpTJ48uf/TioiIiFhMYiIMGWIwZIgBtJ+ybUcHHD586pMLfT47e/Yk0txsp6HB2ecNW7rYbObxIto8XkQbxwto83gBfXJxbYQU2r0V22eTPgtjwzBYuXIljz32GG63m9LSUrxeL8OHDw9pN2HCBGbOnBmxoCIiIiLxzuEguLyiLx6Ph0OHfLS2QnOznaYmG01NNhobbSGPO/+ceNzc3NXOTnOzDZ/Pzv/9X2eb5ubO559Ose10Qnp6Trdiu+eZ7PCKbavObPdZGNfU1JCbm0tOTg7QWQBv27atW2EcDZkLFpCwbx/utraov/bJEhITLZEDlMXKOcA6WaySA6yVxVFYCKWlsY4hItIjm61zWUdqqoHb3T9/p2lyWsW2YaTh97f2Wmx3tT/dme2Ti+lwiu2CAhtDhvRPP/Skz8I4EAjg/t6/hNvtZt++fd3abd26lT179jBkyBBmzJiBp/Oq4CE2btzIxo0bASgvL++xzak4UlOx2WwkWuCCg1bJAcpi5RxgnSxWyQEWy2K3n/ZYJCISz0632PZ4kvH56k7Z5uRiu7Gxa/b61DPbjY324HY4xfYvftFBWdkPefen1mdhbJrd15bYTpr/Liws5MorryQxMZGKigpWrFhBWQ+pi4qKKCoqCj7uuph32EpLQy4CHktWyQHKYuUcYJ0sVskB8Z9l6NChEUojIhKfIj2z3VVojxx5Tv/85b3oszB2u934/f7gY7/fT3Z2dkibjIyM4HZRURFr167tx4giItKTvk6MbmtrY/ny5ezfv5+MjAzmzJnD4MGDAVi/fj2bNm3Cbrfz85//nPz8/Fi8BRGRXvVUbHs8EMl5lT7vJJ6Xl0dtbS0HDx6kvb2dyspKvF5vSJvDhw8Ht6uqqmKy/lhE5GzSdWL0I488wjPPPMOHH37I119/HdJm06ZNpKen87vf/Y4bbrghOGnx9ddfU1lZydNPP82jjz7KypUrMYy+TwQSERno+pwxdjgc3H333SxatAjDMJg4cSIjRoxg3bp15OXl4fV6effdd6mqqsLhcOB0Opk1a1Y0souInLXCOTG6qqqK2267DYBx48axatUqTNNk27ZtTJgwgcTERAYPHkxubi41NTVccMEFMXkvIiJWEdZ1jAsKCigoKAjZN3369OB2SUkJJSUl/ZtMRER6Fc6J0d9v43A4SEtLo6GhgUAgwOjv3T/X5XIRCAS6vcYPPWEaICEhwTInN1oli1VygHWyWCUHKIuVc0Dks+jOdyIicSicE6N7a9PT/p784BOmif8TLQdyDrBOFqvkAGWxcg448yzhnjTd5xpjERGxnnBOjP5+m46ODpqbm3E6nd2eGwgEgncuFRE5m6kwFhGJQ+GcGF1YWMjmzZsB2LJlC2PHjsVms+H1eqmsrKStrY2DBw9SW1vLqFGjYvAuRESsRUspRETiUDgnRk+aNInly5dz33334XQ6mTNnDgAjRoxg/PjxzJ07F7vdzsyZM7HbNU8iIqLCWEQkTvV1YnRSUhJz587t8bnTpk1j2rRpEc0nIhJvNEUgIiIiIoIKYxERERERAGxmuNftEREREREZwOJuxnjevHmxjgBYJwcoS0+skgOsk8UqOUBZziZW6l+rZLFKDrBOFqvkAGXpiVVyQOSzxF1hLCIiIiISCSqMRUREREQAx8KFCxfGOsTpOv/882MdAbBODlCWnlglB1gni1VygLKcTazUv1bJYpUcYJ0sVskBytITq+SAyGbRyXciIiIiImgphYiIiIgIYNE73z377LNs376drKwsli5d2u24aZqsXr2aHTt2kJyczKxZsyI2rd5Xlk8//ZTf/OY3DB48GIArrriCW2+9td9z+Hw+VqxYwZEjR7DZbBQVFfGTn/wkpE00+iWcHNHqk2PHjlFWVkZ7ezsdHR2MGzeO22+/PaRNW1sby5cvZ//+/WRkZDBnzpxgrmhn2bx5M2vWrMHlcgEwdepUJk+e3O9ZAAzDYN68ebhcrm5n8EarT8LJEq0+uffee0lJScFut+NwOCgvLw85Hs0xZSDSmN2dVcbscLNEo180ZvdOY3Z3MRu3TQv69NNPzc8//9ycO3duj8c//vhjc9GiRaZhGObevXvN0tLSmGXZtWuX+dRTT0Xs9bsEAgHz888/N03TNJubm83Zs2ebX331VUibaPRLODmi1SeGYZgtLS2maZpmW1ubWVpaau7duzekzXvvvWe+8MILpmma5l/+8hfz6aefjlmWP/3pT+bLL78ckdc/2VtvvWUuW7asx3+HaPVJOFmi1SezZs0y6+rqej0ezTFlINKY3Z1Vxuxws0SjXzRm905jdnexGrctuZRizJgxOJ3OXo9XVVVxzTXXYLPZuOCCC2hqauLw4cMxyRIt2dnZwd+EUlNTGTZsGIFAIKRNNPolnBzRYrPZSElJAaCjo4OOjg5sNltIm6qqKq699loAxo0bx65duzAjsKw+nCzR4vf72b59e6+/xUerT8LJYhXRHFMGIo3Z3VllzA43SzRozO6ZxuwzE6nvH0supehLIBDA4/EEH7vdbgKBANnZ2THJ89lnn/Hggw+SnZ3NnXfeyYgRIyL6egcPHuSLL75g1KhRIfuj3S+95YDo9YlhGDz88MN89913TJkyhdGjR4ccDwQCuN1uABwOB2lpaTQ0NJCZmRn1LABbt25lz549DBkyhBkzZoT8e/WX3//+99xxxx20tLT0eDyafdJXFohOnwAsWrQIgOuuu46ioqKQY1YbUwYaq/Xv2TpmnyoLRKdfNGZ3pzG7d7EYt+OyMO7pN6VY/aZ33nnn8eyzz5KSksL27dtZvHgxv/3tbyP2eq2trSxdupS77rqLtLS0kGPR7JdT5Yhmn9jtdhYvXkxTUxNLlizhyy+/ZOTIkcHj0eyTvrIUFhZy5ZVXkpiYSEVFBStWrKCsrKxfM3z88cdkZWVx/vnn8+mnn/bYJlp9Ek6WaPQJwBNPPIHL5aKuro4nn3ySoUOHMmbMmOBxK40pA5GV+vdsHbP7yhKtftGYHUpjdu9iNW5bcilFX9xuNz6fL/jY7/fHbOYhLS0t+HFMQUEBHR0d1NfXR+S12tvbWbp0KVdffTVXXHFFt+PR6pe+ckSzT7qkp6czZswYqqurQ/a73W78fj/Q+XFZc3NzxD9m7S1LRkYGiYmJABQVFbF///5+f+29e/dSVVXFvffey7Jly9i1a1e3H27R6pNwskSjT4DgiSJZWVlcdtll1NTUhBy30pgyEFmpf8/GMTucLNEetzVmd9KY3btYjdtxWRh7vV4++OADTNPks88+Iy0tLWaD7JEjR4K/tdTU1GAYBhkZGf3+OqZp8vzzzzNs2DBuvPHGHttEo1/CyRGtPqmvr6epqQnoPMP4r3/9K8OGDQtpU1hYyObNmwHYsmULY8eOjchv2uFk+f7ap6qqKoYPH97vOUpKSnj++edZsWIFc+bM4aKLLmL27NkhbaLVJ+FkiUaftLa2Bj8WbG1t5ZNPPgmZFQJrjSkDkZX692wbs8PNEo1+0ZjdncbsnsVy3LbkUoply5axe/duGhoauOeee7j99ttpb28H4Prrr+fSSy9l+/btzJ49m6SkJGbNmhWzLFu2bKGiogKHw0FSUhJz5syJyH/YvXv38sEHHzBy5EgefPBBAH72s58Ff1uKVr+EkyNafXL48GFWrFiBYRiYpsn48eMpLCxk3bp15OXl4fV6mTRpEsuXL+e+++7D6XQyZ86cfs8RbpZ3332XqqoqHA4HTqczov9vTxaLPgknSzT6pK6ujiVLlgCdsy1XXXUV+fn5VFRUANEfUwYijdndWWXMDjdLNPpFY3b4zuYxG2I7buvOdyIiIiIixOlSChERERGR/qbCWEREREQEFcYiIiIiIoAKYxERERERQIWxiIiIiAigwlhEREREBFBhLCIiIiICqDAWEREREQHg/wFkECI/5U8x7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Can probs ignore from here down\n",
    "\n",
    "banned_dict = {}\n",
    "\n",
    "for word in banned_words_no_punct.split(\" \"):\n",
    "    if word in banned_dict:\n",
    "        banned_dict[word] += 1\n",
    "    else:\n",
    "        banned_dict[word] = 1\n",
    "        \n",
    "print(dict(list(banned_dict.items())[0: 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Seriously': 52, 'The': 2331, 'pats': 6, 'havent': 245, 'won': 77}\n"
     ]
    }
   ],
   "source": [
    "not_banned_dict = {}\n",
    "\n",
    "for word in not_banned_words_no_punct.split(\" \"):\n",
    "    if word in not_banned_dict:\n",
    "        not_banned_dict[word] += 1\n",
    "    else:\n",
    "        not_banned_dict[word] = 1\n",
    "        \n",
    "print(dict(list(not_banned_dict.items())[0: 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I': 0, 'know': 39, 'that': 0, 'strenuous': 4, 'ever': 1}\n"
     ]
    }
   ],
   "source": [
    "banned_counts = {}\n",
    "for word in list(banned_dict.keys()):\n",
    "    if word in not_banned_dict:\n",
    "        banned_counts[word] = banned_dict[word] - not_banned_dict[word]\n",
    "        if banned_counts[word] < 0:\n",
    "            banned_counts[word] = 0\n",
    "    else:\n",
    "        banned_counts[word] = banned_dict[word]\n",
    "\n",
    "print(dict(list(banned_counts.items())[0: 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Seriously': 0, 'The': 733, 'pats': 6, 'havent': 37, 'won': 66}\n"
     ]
    }
   ],
   "source": [
    "not_banned_counts = {}\n",
    "for word in list(not_banned_dict.keys()):\n",
    "    if word in banned_dict:\n",
    "        not_banned_counts[word] = not_banned_dict[word] - banned_dict[word]\n",
    "        if not_banned_counts[word] < 0:\n",
    "            not_banned_counts[word] = 0\n",
    "    else:\n",
    "        not_banned_counts[word] = not_banned_dict[word]\n",
    "        \n",
    "print(dict(list(not_banned_counts.items())[0: 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCounts(str):\n",
    "    \"\"\"\n",
    "    get how many times the words show up in the banned dictionary - how many times it shows up in the not banned dictionary\n",
    "    \"\"\"\n",
    "    weight = 0\n",
    "    for word in str.split(\" \"):\n",
    "        if word in banned_counts:\n",
    "            weight += banned_counts[word]\n",
    "        if word in not_banned_counts:\n",
    "            weight -= not_banned_counts[word]\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBannedCount(str):\n",
    "    \"\"\"\n",
    "    get how many times the words show up in the banned dictionary \n",
    "    \"\"\"\n",
    "    weight = 0\n",
    "    for word in str.split(\" \"):\n",
    "        if word in banned_counts:\n",
    "            weight += banned_counts[word]\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNotBannedCount(str):\n",
    "    \"\"\"\n",
    "    get how many times the words show up in the not banned dictionary \n",
    "    \"\"\"\n",
    "    weight = 0\n",
    "    for word in str.split(\" \"):\n",
    "        if word in not_banned_counts:\n",
    "            weight += not_banned_counts[word]\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "feature = []\n",
    "#labels = np.array(int)\n",
    "labels = []\n",
    "feature1 = []\n",
    "feature2 = []\n",
    "feature3 = []\n",
    "count = 0\n",
    "for comment in banned_comments:\n",
    "    if count < 10000:\n",
    "        feature1.append(float(getBannedCount(comment)))\n",
    "        feature2.append(float(getNotBannedCount(comment)))\n",
    "        feature3.append(float(getCounts(comment)))\n",
    "        labels.append(float(1))\n",
    "        count += 1\n",
    "    else:\n",
    "        break\n",
    "        #labels = np.append(labels, 1)\n",
    "        \n",
    "count = 0\n",
    "for comment in not_banned_comments:\n",
    "    if count < 10000:\n",
    "        feature1.append(float(getBannedCount(comment)))\n",
    "        feature2.append(float(getNotBannedCount(comment)))\n",
    "        feature3.append(float(getCounts(comment)))\n",
    "        labels.append(float(0))\n",
    "        #labels = np.append(labels, 0)\n",
    "        count += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "feature.append(feature1)\n",
    "feature.append(feature2)\n",
    "feature.append(feature3)\n",
    "labels1 = []\n",
    "labels1.append(labels)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.array([np.array(xi) for xi in feature])\n",
    "type(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = np.array([np.array(xi) for xi in labels1])\n",
    "type(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is: (3, 20000)\n",
      "The shape of Y is: (1, 20000)\n",
      "I have 800 training sample!\n"
     ]
    }
   ],
   "source": [
    "shape_X = features.shape\n",
    "shape_Y = label.shape\n",
    "m = 2 * 400\n",
    "\n",
    "print ('The shape of X is: ' + str(shape_X))\n",
    "print ('The shape of Y is: ' + str(shape_Y))\n",
    "print ('I have %d training sample!' % (m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layerSizes(X, Y):\n",
    "    \"\"\"\n",
    "    X -- input dataset of shape \n",
    "    Y -- labels of shape\n",
    "    \"\"\"\n",
    "    input_layer_size= X.shape[0]\n",
    "    hidden_layer_size= 4\n",
    "    output_layer_size= Y.shape[0]\n",
    "    # hardcode as 1 bc we have to \n",
    "    \n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    input_layer_size -- the size of the input layer\n",
    "    hidden_layer_size -- the size of the hidden layer\n",
    "    output_layer_size -- the size of the output layer\n",
    "    \"\"\"\n",
    "    \n",
    "    return (input_layer_size, hidden_layer_size, output_layer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(input_size, hidden_size, output_size):\n",
    "    \"\"\"\n",
    "    input_size-- size of the input layer\n",
    "    hidden_size -- size of the hidden layer\n",
    "    output_size-- size of the output layer\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(2)  # you can pick any seed in this case\n",
    "    \n",
    "    Weight1 = np.random.randn(hidden_size,input_size) * 0.01\n",
    "    Weight2 = np.random.randn(output_size,hidden_size) * 0.01\n",
    "    bias1 = np.zeros(shape=(hidden_size, 1))\n",
    "    bias2 = np.zeros(shape=(output_size, 1))\n",
    "    \n",
    "    parameters = {\"Weight1\": Weight1,\n",
    "                  \"bias1\": bias1,\n",
    "                  \"Weight2\": Weight2,\n",
    "                  \"bias2\": bias2}\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Returns:\n",
    "    params -- python dictionary containing your parameters:\n",
    "                    W1 -- weight matrix of shape \n",
    "                    b1 -- bias vector of shape \n",
    "                    W2 -- weight matrix of shape \n",
    "                    b2 -- bias vector of shape\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X, parameters):\n",
    "    \"\"\"\n",
    "    X -- input data of size\n",
    "    parameters -- python dictionary containing your parameters (output of initialization function)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    # Retrieve each parameter from the dictionary \"parameters\"\n",
    "    Weight1 = parameters['Weight1']\n",
    "    bias1 = parameters['bias1']\n",
    "    Weight2 = parameters['Weight2']\n",
    "    bias2 = parameters['bias2']\n",
    "    \n",
    "    # Implement Forward Propagation to calculate A2 (probabilities)\n",
    "    Z1 = np.dot(Weight1,X) + bias1\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(Weight2,A1) + bias2\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    #Values needed in the backpropagation are stored in cache. Later, it will be given to back propagation.\n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    A2 -- The sigmoid output of the second activation\n",
    "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\"\n",
    "    \"\"\"\n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(A2, Y, parameters):\n",
    "    \"\"\"\n",
    "    Computes the cross-entropy cost given in equation (13)\n",
    "    \n",
    "    Arguments:\n",
    "    A2 -- The sigmoid output of the second activation\n",
    "    Y -- \"true\" labels vector of shape \n",
    "    parameters -- python dictionary containing your parameters W1, b1, W2 and b2\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1]  # number of example \n",
    "\n",
    "    # Compute the cross-entropy cost\n",
    "    logprobs = np.multiply(np.log(A2), Y[0]) + np.multiply((1 - Y[0]), np.log(1 - A2))\n",
    "    cost = - np.sum(logprobs) / m\n",
    "    \n",
    "    ### Remember that, if you want to use different cross-entropy loss, you need to change logprobs and cost accordingly\n",
    "    \n",
    "    cost = float(np.squeeze(cost))   \n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(parameters, cache, X, Y):\n",
    "    \"\"\"\n",
    "    \n",
    "    parameters -- dictionary containing our parameters \n",
    "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\".\n",
    "    X -- input data \n",
    "    Y -- \"true\" labels vector \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # Copy W1 and W2 from the dictionary \"parameters\"\n",
    "    Weight1 = parameters['Weight1']\n",
    "    Weight2 = parameters['Weight2']\n",
    "    \n",
    "        \n",
    "    # Copy A1 and A2 from dictionary \"cache\".\n",
    "    \n",
    "    A1 = cache['A1']\n",
    "    A2 = cache['A2']\n",
    "    \n",
    "    #  calculate dW1, db1, dW2, db2. \n",
    "    \n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = (1 / m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = np.multiply(np.dot(Weight2.T, dZ2), 1 - np.power(A1, 2))\n",
    "    dW1 = (1 / m) * np.dot(dZ1, X.T)\n",
    "    db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    \n",
    "    gradient = {\"dW1\": dW1,\n",
    "                \"db1\": db1,\n",
    "                \"dW2\": dW2,\n",
    "                \"db2\": db2}\n",
    "    \n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate = 0.5):\n",
    "    \"\"\"\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients \n",
    "    \"\"\"\n",
    "    # Copy the following parameter from the dictionary \"parameters\"\n",
    "    Weight1 = parameters['Weight1']\n",
    "    Weight2 = parameters['Weight2']\n",
    "    bias1 = parameters['bias1']\n",
    "    bias2 = parameters['bias2']\n",
    "    \n",
    "    # Copy each gradient from the dictionary \"grads\"\n",
    "    dW1 = grads['dW1']\n",
    "    db1 = grads['db1']\n",
    "    dW2 = grads['dW2']\n",
    "    db2 = grads['db2']\n",
    "    \n",
    "    # Update rule for each parameter\n",
    "    Weight1 = Weight1 - learning_rate * dW1\n",
    "    Weight2 = Weight2 - learning_rate * dW2\n",
    "    bias1 = bias1 - learning_rate * db1\n",
    "    bias2 = bias2 - learning_rate * db2\n",
    "    \n",
    "    parameters = {\"Weight1\": Weight1,\n",
    "                  \"Weight2\": Weight2,\n",
    "                  \"bias1\": bias1,\n",
    "                  \"bias2\": bias2}\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters\n",
    "    \"\"\"\n",
    "    #print(parameters)\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, n_h, num_iterations = 1000, print_cost=True):\n",
    "    \"\"\"\n",
    "    X -- dataset\n",
    "    Y -- labels\n",
    "    n_h -- size of the hidden layer\n",
    "    num_iterations -- Number of iterations in gradient descent\n",
    "    print_cost -- if True, print the cost in every 100 iterations\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(4)\n",
    "    n_x = layerSizes(X, Y)[0]\n",
    "    n_y = layerSizes(X, Y)[2]\n",
    "    \n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "    Weight1 = parameters['Weight1']\n",
    "    bias1 = parameters['bias1']\n",
    "    Weight2 = parameters['Weight2']\n",
    "    bias2 = parameters['bias2']\n",
    "    \n",
    "    # gradient descent\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "         \n",
    "        # Call the Forward propagation with X, and parameters.\n",
    "        A2, cache = forward_prop(X, parameters)\n",
    "        \n",
    "        # Call the Cost function with A2, Y and parameters.\n",
    "        cost = compute_cost(A2, Y, parameters)\n",
    " \n",
    "        # Call Backpropagation with Inputs, parameters, cache, X and Y.\n",
    "        grads = backward_propagation(parameters, cache, X, Y)\n",
    " \n",
    "        # Update gradient descent parameter with  parameters and grads and learning rate.\n",
    "        parameters = update_parameters(parameters, grads)\n",
    "        \n",
    "        \n",
    "        # Print the cost every 100 iterations\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(parameters, X):\n",
    "    \"\"\"\n",
    "    Using the learned parameters, predicts a class for each example in X\n",
    "    \n",
    "    parameters -- python dictionary containing your parameters \n",
    "    X -- input data\n",
    "    \n",
    "    Returns\n",
    "    predictions -- vector of predictions of our model (red: 0 / blue: 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Computes probabilities using forward propagation, and classifies to 0/1 using 0.5 as the threshold.\n",
    "    A2, cache = forward_prop(X,parameters)\n",
    "    predictions = (A2 > 0.5)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693369\n",
      "Cost after iteration 100: 0.691049\n",
      "Cost after iteration 200: 0.690562\n",
      "Cost after iteration 300: 0.690457\n",
      "Cost after iteration 400: 0.690391\n",
      "Cost after iteration 500: 0.690337\n",
      "Cost after iteration 600: 0.690291\n",
      "Cost after iteration 700: 0.690251\n",
      "Cost after iteration 800: 0.690216\n",
      "Cost after iteration 900: 0.690187\n",
      "Accuracy: 51%\n"
     ]
    }
   ],
   "source": [
    "# Build a model with a n_h-dimensional hidden layer\n",
    "parameters = model(features, label, n_h = 1, num_iterations = 1000, print_cost=True)\n",
    "\n",
    "# Plot the decision boundary\n",
    "# plot_decision_boundary(lambda x: predict(parameters, x.T), features, label[0])\n",
    "# plt.title(\"Decision Boundary for hidden layer size \" + str(4));\n",
    "\n",
    "# Print accuracy\n",
    "predictions = predict(parameters, features)\n",
    "print ('Accuracy: %d' % float((np.dot(label,predictions.T) + np.dot(1-label,1-predictions.T))/float(label.size)*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
